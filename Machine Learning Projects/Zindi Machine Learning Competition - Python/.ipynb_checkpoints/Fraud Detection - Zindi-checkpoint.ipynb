{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb198a7",
   "metadata": {},
   "source": [
    "Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9530f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import itertools\n",
    "\n",
    "import scipy\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4344f3",
   "metadata": {},
   "source": [
    "Data ingestion\n",
    "\n",
    "Convert csvs to Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b908663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887059, 16) (864499, 16) (58069, 5) (135493, 6)\n"
     ]
    }
   ],
   "source": [
    "invoice_test = pd.read_csv('invoice_test.csv', low_memory=False)\n",
    "invoice_train = pd.read_csv('invoice_train.csv', low_memory=False)\n",
    "client_test = pd.read_csv('client_test.csv', low_memory=False)\n",
    "client_train = pd.read_csv('client_train.csv', low_memory=False)\n",
    "sample_submission = pd.read_csv('SampleSubmission.csv', low_memory=False)\n",
    "\n",
    "print(invoice_test.shape, invoice_train.shape, client_test.shape, client_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd256e",
   "metadata": {},
   "source": [
    "Data Exploration: This page: https://zindi.africa/competitions/ai-hack-tunisia-4-predictive-analytics-challenge-1/data has the data dictionary. I'm using \"target\" as my label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d56d0769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   disrict        135493 non-null  int64  \n",
      " 1   client_id      135493 non-null  object \n",
      " 2   client_catg    135493 non-null  int64  \n",
      " 3   region         135493 non-null  int64  \n",
      " 4   creation_date  135493 non-null  object \n",
      " 5   target         135493 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "client_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f85dc67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 864499 entries, 0 to 864498\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   client_id             864499 non-null  object\n",
      " 1   invoice_date          864499 non-null  object\n",
      " 2   tarif_type            864499 non-null  int64 \n",
      " 3   counter_number        864499 non-null  int64 \n",
      " 4   counter_statue        864499 non-null  int64 \n",
      " 5   counter_code          864499 non-null  int64 \n",
      " 6   reading_remarque      864499 non-null  int64 \n",
      " 7   counter_coefficient   864499 non-null  int64 \n",
      " 8   consommation_level_1  864499 non-null  int64 \n",
      " 9   consommation_level_2  864499 non-null  int64 \n",
      " 10  consommation_level_3  864499 non-null  int64 \n",
      " 11  consommation_level_4  864499 non-null  int64 \n",
      " 12  old_index             864499 non-null  int64 \n",
      " 13  new_index             864499 non-null  int64 \n",
      " 14  months_number         864499 non-null  int64 \n",
      " 15  counter_type          864498 non-null  object\n",
      "dtypes: int64(13), object(3)\n",
      "memory usage: 105.5+ MB\n"
     ]
    }
   ],
   "source": [
    "invoice_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21a8ef",
   "metadata": {},
   "source": [
    "Feature engineering\n",
    "\n",
    "Recoding certain columns, formats, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4eee4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_change(cl, inv):\n",
    "\n",
    "    cl['client_catg'] = cl['client_catg'].astype('category')\n",
    "    cl['disrict'] = cl['disrict'].astype('category')\n",
    "    cl['region'] = cl['region'].astype('category')\n",
    "    cl['region_group'] = cl['region'].apply(lambda x: 100 if x<100 else 300 if x>300 else 200)\n",
    "    cl['creation_date'] = pd.to_datetime(cl['creation_date'])\n",
    "    \n",
    "    cl['coop_time'] = (2019 - cl['creation_date'].dt.year)*12 - cl['creation_date'].dt.month\n",
    "\n",
    "    inv['counter_type'] = inv['counter_type'].map({\"ELEC\":1,\"GAZ\":0})\n",
    "    inv['counter_statue'] = inv['counter_statue'].map({0:0,1:1,2:2,3:3,4:4,5:5,769:5,'0':0,'5':5,'1':1,'4':4,'A':0,618:5,269375:5,46:5,420:5})\n",
    "    \n",
    "    inv['invoice_date'] = pd.to_datetime(inv['invoice_date'], dayfirst=True)\n",
    "    inv['invoice_month'] = inv['invoice_date'].dt.month\n",
    "    inv['invoice_year'] = inv['invoice_date'].dt.year\n",
    "    inv['is_weekday'] = ((pd.DatetimeIndex(inv.invoice_date).dayofweek) // 5 == 1).astype(float)\n",
    "    inv['delta_index'] = inv['new_index'] - inv['old_index']\n",
    "    \n",
    "    return cl, inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8789c3a4",
   "metadata": {},
   "source": [
    "I apply my feature changes to the training and test data. After this point, I don't touch my testing data to prevent leakeage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85071729",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train1, invoice_train1 = feature_change(client_train, invoice_train)\n",
    "client_test1, invoice_test1 = feature_change(client_test, invoice_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ca430",
   "metadata": {},
   "source": [
    "I write a function to create aggregate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1e13d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_feature(invoice, client_df, agg_stat):\n",
    "    \n",
    "    invoice['delta_time'] = invoice.sort_values(['client_id','invoice_date']).groupby('client_id')['invoice_date'].diff().dt.days.reset_index(drop=True)\n",
    "    agg_trans = invoice.groupby('client_id')[agg_stat+['delta_time']].agg(['mean','std','min','max'])\n",
    "    \n",
    "    agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "\n",
    "    df = invoice.groupby('client_id').size().reset_index(name='transactions_count')\n",
    "    agg_trans = pd.merge(df, agg_trans, on='client_id', how='left')\n",
    "    \n",
    "    weekday_avg = invoice.groupby('client_id')[['is_weekday']].agg(['mean'])\n",
    "    weekday_avg.columns = ['_'.join(col).strip() for col in weekday_avg.columns.values]\n",
    "    weekday_avg.reset_index(inplace=True)\n",
    "    client_df = pd.merge(client_df, weekday_avg, on='client_id', how='left')\n",
    "    \n",
    "    full_df = pd.merge(client_df, agg_trans, on='client_id', how='left')\n",
    "    \n",
    "    full_df['invoice_per_cooperation'] = full_df['transactions_count'] / full_df['coop_time']\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ef64e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {}\n",
    "aggs['consommation_level_1'] = ['mean']\n",
    "aggs['consommation_level_2'] = ['mean']\n",
    "aggs['consommation_level_3'] = ['mean']\n",
    "aggs['consommation_level_4'] = ['mean']\n",
    "agg_trans = invoice_train.groupby(['client_id', 'counter_type']).agg(aggs)\n",
    "agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "agg_trans.reset_index(inplace=True)\n",
    "\n",
    "agg_trans1 = agg_trans\n",
    "\n",
    "aggs = {}\n",
    "aggs['consommation_level_1_mean'] = ['mean']\n",
    "aggs['consommation_level_2_mean'] = ['mean']\n",
    "aggs['consommation_level_3_mean'] = ['mean']\n",
    "aggs['consommation_level_4_mean'] = ['mean']\n",
    "agg_trans = agg_trans1.groupby(['client_id']).agg(aggs)\n",
    "agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "agg_trans.reset_index(inplace=True)\n",
    "\n",
    "df = (invoice_train.groupby('client_id')\n",
    "          .size()\n",
    "          .reset_index(name='{}transactions_count'.format('1')))\n",
    "agg_trans = pd.merge(df, agg_trans, on='client_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed92769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stat_columns = [\n",
    " 'tarif_type',\n",
    " 'counter_number',\n",
    " 'counter_statue',\n",
    " 'counter_code',\n",
    " 'reading_remarque',\n",
    " 'consommation_level_1',\n",
    " 'consommation_level_2',\n",
    " 'consommation_level_3',\n",
    " 'consommation_level_4',\n",
    " 'old_index',\n",
    " 'new_index',\n",
    " 'months_number',\n",
    " 'counter_type',\n",
    " 'invoice_month',\n",
    " 'invoice_year',\n",
    " 'delta_index'\n",
    "]\n",
    "\n",
    "train_df1 = agg_feature(invoice_train1, client_train1, agg_stat_columns)\n",
    "test_df1 = agg_feature(invoice_test1, client_test1, agg_stat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b6219",
   "metadata": {},
   "source": [
    "I merge my dataframe with my new aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c35f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['disrict', 'client_id', 'client_catg', 'region', 'creation_date',\n",
      "       'target', 'region_group', 'coop_time', 'is_weekday_mean',\n",
      "       'transactions_count', 'tarif_type_mean', 'tarif_type_std',\n",
      "       'tarif_type_min', 'tarif_type_max', 'counter_number_mean',\n",
      "       'counter_number_std', 'counter_number_min', 'counter_number_max',\n",
      "       'counter_statue_mean', 'counter_statue_std', 'counter_statue_min',\n",
      "       'counter_statue_max', 'counter_code_mean', 'counter_code_std',\n",
      "       'counter_code_min', 'counter_code_max', 'reading_remarque_mean',\n",
      "       'reading_remarque_std', 'reading_remarque_min', 'reading_remarque_max',\n",
      "       'consommation_level_1_mean', 'consommation_level_1_std',\n",
      "       'consommation_level_1_min', 'consommation_level_1_max',\n",
      "       'consommation_level_2_mean', 'consommation_level_2_std',\n",
      "       'consommation_level_2_min', 'consommation_level_2_max',\n",
      "       'consommation_level_3_mean', 'consommation_level_3_std',\n",
      "       'consommation_level_3_min', 'consommation_level_3_max',\n",
      "       'consommation_level_4_mean', 'consommation_level_4_std',\n",
      "       'consommation_level_4_min', 'consommation_level_4_max',\n",
      "       'old_index_mean', 'old_index_std', 'old_index_min', 'old_index_max',\n",
      "       'new_index_mean', 'new_index_std', 'new_index_min', 'new_index_max',\n",
      "       'months_number_mean', 'months_number_std', 'months_number_min',\n",
      "       'months_number_max', 'counter_type_mean', 'counter_type_std',\n",
      "       'counter_type_min', 'counter_type_max', 'invoice_month_mean',\n",
      "       'invoice_month_std', 'invoice_month_min', 'invoice_month_max',\n",
      "       'invoice_year_mean', 'invoice_year_std', 'invoice_year_min',\n",
      "       'invoice_year_max', 'delta_index_mean', 'delta_index_std',\n",
      "       'delta_index_min', 'delta_index_max', 'delta_time_mean',\n",
      "       'delta_time_std', 'delta_time_min', 'delta_time_max',\n",
      "       'invoice_per_cooperation', '1transactions_count',\n",
      "       'consommation_level_1_mean_mean', 'consommation_level_2_mean_mean',\n",
      "       'consommation_level_3_mean_mean', 'consommation_level_4_mean_mean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df1 = pd.merge(train_df1,agg_trans, on='client_id', how='left')\n",
    "\n",
    "test_df1 = pd.merge(test_df1,agg_trans, on='client_id', how='left')\n",
    "\n",
    "print(train_df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310da2e",
   "metadata": {},
   "source": [
    "One more feature engineering step, I create a range and max mean column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a034bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(df):\n",
    "    \n",
    "    for col in agg_stat_columns:\n",
    "        df[col+'_range'] = df[col+'_max'] - df[col+'_min']\n",
    "        df[col+'_max_mean'] = df[col+'_max']/df[col+'_mean']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3b045a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = new_features(train_df1)\n",
    "test_df2 = new_features(test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d973279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of columns:  29\n",
      "Number of columns now:  116\n"
     ]
    }
   ],
   "source": [
    "print('Initial number of columns: ', len(client_train.columns)+len(invoice_train.columns))\n",
    "print('Number of columns now: ', len(train_df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d45401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(df):\n",
    "\n",
    "    col_drop = ['client_id', 'creation_date']\n",
    "    for col in col_drop:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20231590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = drop(train_df2)\n",
    "test_df = drop(test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df6212a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "X = train_df.drop('target',axis=1)\n",
    "\n",
    "feature_name = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a039f17",
   "metadata": {},
   "source": [
    "Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72c9e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=['reading_remarque_max','counter_statue_min','counter_type_min','counter_type_max','counter_type_range',\n",
    "          'tarif_type_max', 'delta_index_min', 'consommation_level_4_mean']\n",
    "\n",
    "X = X.drop(drop_col, axis=1)\n",
    "test_df = test_df.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594293e",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b45a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "import gc\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial:Trial):\n",
    "    \n",
    "    gc.collect()\n",
    "    models=[]\n",
    "    validScore=0\n",
    "   \n",
    "    model,log = fitLGBM(trial,X,y)\n",
    "    \n",
    "    models.append(model)\n",
    "    gc.collect()\n",
    "    validScore+=log\n",
    "    validScore/=len(models)\n",
    "    \n",
    "    return validScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2736aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fitLGBM(trial,X, y):\n",
    "    \n",
    "    params={\n",
    "        'n_estimators':trial.suggest_int('n_estimators', 0, 1000),\n",
    "        'num_leaves':trial.suggest_int('num_leaves', 2, 512),\n",
    "        'max_depth':trial.suggest_int('max_depth', 2, 128),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.5),\n",
    "        'min_split_gain': trial.suggest_loguniform('min_split_gain', 0.001, 0.1),\n",
    "        'feature_fraction':trial.suggest_uniform('feature_fraction',0.1, 1.0),\n",
    "        'bagging_freq':trial.suggest_int('bagging_freq',0.1,10),\n",
    "        'verbosity': -1,\n",
    "            }\n",
    "    stkfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    res=[]\n",
    "    for i, (tdx, vdx) in enumerate(stkfold.split(X, y)):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                 early_stopping_rounds=30)\n",
    "        preds = model.predict_proba(X_valid)\n",
    "        res.append(roc_auc_score(y_valid, preds[:,1]))\n",
    "    \n",
    "    err = np.mean(res)\n",
    "    \n",
    "    return model, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09630c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's binary_logloss: 0.182041\tvalid_1's binary_logloss: 0.200558\n",
      "[41]\ttraining's binary_logloss: 0.207979\tvalid_1's binary_logloss: 0.210896\n",
      "[301]\ttraining's binary_logloss: 0.181994\tvalid_1's binary_logloss: 0.200547\n",
      "[42]\ttraining's binary_logloss: 0.20783\tvalid_1's binary_logloss: 0.210808\n",
      "[302]\ttraining's binary_logloss: 0.181948\tvalid_1's binary_logloss: 0.20054\n",
      "[43]\ttraining's binary_logloss: 0.207682\tvalid_1's binary_logloss: 0.21072\n",
      "[303]\ttraining's binary_logloss: 0.181902\tvalid_1's binary_logloss: 0.200536\n",
      "[44]\ttraining's binary_logloss: 0.207537\tvalid_1's binary_logloss: 0.210632\n",
      "[304]\ttraining's binary_logloss: 0.181855\tvalid_1's binary_logloss: 0.200522\n",
      "[45]\ttraining's binary_logloss: 0.207391\tvalid_1's binary_logloss: 0.210545\n",
      "[305]\ttraining's binary_logloss: 0.181808\tvalid_1's binary_logloss: 0.200513\n",
      "[46]\ttraining's binary_logloss: 0.207246\tvalid_1's binary_logloss: 0.210461\n",
      "[306]\ttraining's binary_logloss: 0.181762\tvalid_1's binary_logloss: 0.200504\n",
      "[47]\ttraining's binary_logloss: 0.207105\tvalid_1's binary_logloss: 0.210376\n",
      "[307]\ttraining's binary_logloss: 0.181717\tvalid_1's binary_logloss: 0.200491\n",
      "[48]\ttraining's binary_logloss: 0.206963\tvalid_1's binary_logloss: 0.210296\n",
      "[308]\ttraining's binary_logloss: 0.181671\tvalid_1's binary_logloss: 0.200484\n",
      "[49]\ttraining's binary_logloss: 0.206822\tvalid_1's binary_logloss: 0.210214\n",
      "[309]\ttraining's binary_logloss: 0.181627\tvalid_1's binary_logloss: 0.200474\n",
      "[50]\ttraining's binary_logloss: 0.206683\tvalid_1's binary_logloss: 0.210133\n",
      "[310]\ttraining's binary_logloss: 0.181581\tvalid_1's binary_logloss: 0.200465\n",
      "[51]\ttraining's binary_logloss: 0.206546\tvalid_1's binary_logloss: 0.210054\n",
      "[311]\ttraining's binary_logloss: 0.181537\tvalid_1's binary_logloss: 0.200462\n",
      "[52]\ttraining's binary_logloss: 0.206409\tvalid_1's binary_logloss: 0.209975\n",
      "[312]\ttraining's binary_logloss: 0.181493\tvalid_1's binary_logloss: 0.200452\n",
      "[53]\ttraining's binary_logloss: 0.206274\tvalid_1's binary_logloss: 0.209898\n",
      "[313]\ttraining's binary_logloss: 0.181449\tvalid_1's binary_logloss: 0.200442\n",
      "[54]\ttraining's binary_logloss: 0.206142\tvalid_1's binary_logloss: 0.209824\n",
      "[314]\ttraining's binary_logloss: 0.181406\tvalid_1's binary_logloss: 0.200433\n",
      "[55]\ttraining's binary_logloss: 0.20601\tvalid_1's binary_logloss: 0.209749\n",
      "[315]\ttraining's binary_logloss: 0.181363\tvalid_1's binary_logloss: 0.200426\n",
      "[56]\ttraining's binary_logloss: 0.205882\tvalid_1's binary_logloss: 0.209674\n",
      "[316]\ttraining's binary_logloss: 0.18132\tvalid_1's binary_logloss: 0.200418\n",
      "[57]\ttraining's binary_logloss: 0.205754\tvalid_1's binary_logloss: 0.209602\n",
      "[317]\ttraining's binary_logloss: 0.181277\tvalid_1's binary_logloss: 0.200406\n",
      "[58]\ttraining's binary_logloss: 0.205628\tvalid_1's binary_logloss: 0.209526\n",
      "[318]\ttraining's binary_logloss: 0.181232\tvalid_1's binary_logloss: 0.200399\n",
      "[59]\ttraining's binary_logloss: 0.205501\tvalid_1's binary_logloss: 0.209453\n",
      "[319]\ttraining's binary_logloss: 0.181189\tvalid_1's binary_logloss: 0.200393\n",
      "[60]\ttraining's binary_logloss: 0.205377\tvalid_1's binary_logloss: 0.209381\n",
      "[320]\ttraining's binary_logloss: 0.181144\tvalid_1's binary_logloss: 0.200386\n",
      "[61]\ttraining's binary_logloss: 0.205256\tvalid_1's binary_logloss: 0.209311\n",
      "[321]\ttraining's binary_logloss: 0.181099\tvalid_1's binary_logloss: 0.20038\n",
      "[62]\ttraining's binary_logloss: 0.205137\tvalid_1's binary_logloss: 0.209239\n",
      "[322]\ttraining's binary_logloss: 0.181054\tvalid_1's binary_logloss: 0.200374\n",
      "[63]\ttraining's binary_logloss: 0.205015\tvalid_1's binary_logloss: 0.209165\n",
      "[323]\ttraining's binary_logloss: 0.181011\tvalid_1's binary_logloss: 0.200363\n",
      "[64]\ttraining's binary_logloss: 0.204893\tvalid_1's binary_logloss: 0.209097\n",
      "[324]\ttraining's binary_logloss: 0.180968\tvalid_1's binary_logloss: 0.200352\n",
      "[65]\ttraining's binary_logloss: 0.204774\tvalid_1's binary_logloss: 0.209027\n",
      "[325]\ttraining's binary_logloss: 0.180923\tvalid_1's binary_logloss: 0.200343\n",
      "[66]\ttraining's binary_logloss: 0.204655\tvalid_1's binary_logloss: 0.208958\n",
      "[326]\ttraining's binary_logloss: 0.180878\tvalid_1's binary_logloss: 0.200335\n",
      "[67]\ttraining's binary_logloss: 0.204538\tvalid_1's binary_logloss: 0.208891\n",
      "[327]\ttraining's binary_logloss: 0.180834\tvalid_1's binary_logloss: 0.200328\n",
      "[68]\ttraining's binary_logloss: 0.204422\tvalid_1's binary_logloss: 0.208825\n",
      "[328]\ttraining's binary_logloss: 0.180791\tvalid_1's binary_logloss: 0.200323\n",
      "[69]\ttraining's binary_logloss: 0.204307\tvalid_1's binary_logloss: 0.208758\n",
      "[329]\ttraining's binary_logloss: 0.180748\tvalid_1's binary_logloss: 0.200317\n",
      "[70]\ttraining's binary_logloss: 0.204189\tvalid_1's binary_logloss: 0.208693\n",
      "[330]\ttraining's binary_logloss: 0.180705\tvalid_1's binary_logloss: 0.200315\n",
      "[71]\ttraining's binary_logloss: 0.204075\tvalid_1's binary_logloss: 0.208631\n",
      "[331]\ttraining's binary_logloss: 0.180664\tvalid_1's binary_logloss: 0.200307\n",
      "[72]\ttraining's binary_logloss: 0.203959\tvalid_1's binary_logloss: 0.208567\n",
      "[332]\ttraining's binary_logloss: 0.180621\tvalid_1's binary_logloss: 0.200304\n",
      "[73]\ttraining's binary_logloss: 0.203846\tvalid_1's binary_logloss: 0.208509\n",
      "[333]\ttraining's binary_logloss: 0.180578\tvalid_1's binary_logloss: 0.200298\n",
      "[74]\ttraining's binary_logloss: 0.203732\tvalid_1's binary_logloss: 0.208449\n",
      "[334]\ttraining's binary_logloss: 0.180536\tvalid_1's binary_logloss: 0.200296\n",
      "[75]\ttraining's binary_logloss: 0.203623\tvalid_1's binary_logloss: 0.208389\n",
      "[335]\ttraining's binary_logloss: 0.180495\tvalid_1's binary_logloss: 0.200289\n",
      "[76]\ttraining's binary_logloss: 0.203511\tvalid_1's binary_logloss: 0.208329\n",
      "[336]\ttraining's binary_logloss: 0.180453\tvalid_1's binary_logloss: 0.200278\n",
      "[77]\ttraining's binary_logloss: 0.2034\tvalid_1's binary_logloss: 0.20827\n",
      "[337]\ttraining's binary_logloss: 0.180412\tvalid_1's binary_logloss: 0.200273\n",
      "[78]\ttraining's binary_logloss: 0.203288\tvalid_1's binary_logloss: 0.20821\n",
      "[79]\ttraining's binary_logloss: 0.203177\tvalid_1's binary_logloss: 0.208151\n",
      "[338]\ttraining's binary_logloss: 0.180369\tvalid_1's binary_logloss: 0.200266\n",
      "[80]\ttraining's binary_logloss: 0.203066\tvalid_1's binary_logloss: 0.208093\n",
      "[339]\ttraining's binary_logloss: 0.180328\tvalid_1's binary_logloss: 0.200262\n",
      "[81]\ttraining's binary_logloss: 0.202957\tvalid_1's binary_logloss: 0.208035\n",
      "[340]\ttraining's binary_logloss: 0.180286\tvalid_1's binary_logloss: 0.200256\n",
      "[82]\ttraining's binary_logloss: 0.202847\tvalid_1's binary_logloss: 0.207977\n",
      "[341]\ttraining's binary_logloss: 0.180244\tvalid_1's binary_logloss: 0.200251\n",
      "[83]\ttraining's binary_logloss: 0.202739\tvalid_1's binary_logloss: 0.207919\n",
      "[342]\ttraining's binary_logloss: 0.180201\tvalid_1's binary_logloss: 0.200246\n",
      "[84]\ttraining's binary_logloss: 0.202631\tvalid_1's binary_logloss: 0.207862\n",
      "[343]\ttraining's binary_logloss: 0.18016\tvalid_1's binary_logloss: 0.200241\n",
      "[85]\ttraining's binary_logloss: 0.202524\tvalid_1's binary_logloss: 0.207806\n",
      "[344]\ttraining's binary_logloss: 0.180118\tvalid_1's binary_logloss: 0.200235\n",
      "[86]\ttraining's binary_logloss: 0.202419\tvalid_1's binary_logloss: 0.207752\n",
      "[345]\ttraining's binary_logloss: 0.180077\tvalid_1's binary_logloss: 0.200232\n",
      "[87]\ttraining's binary_logloss: 0.202316\tvalid_1's binary_logloss: 0.207697\n",
      "[346]\ttraining's binary_logloss: 0.180037\tvalid_1's binary_logloss: 0.200226\n",
      "[88]\ttraining's binary_logloss: 0.202212\tvalid_1's binary_logloss: 0.207643\n",
      "[347]\ttraining's binary_logloss: 0.179996\tvalid_1's binary_logloss: 0.20022\n",
      "[89]\ttraining's binary_logloss: 0.202109\tvalid_1's binary_logloss: 0.207589\n",
      "[348]\ttraining's binary_logloss: 0.179956\tvalid_1's binary_logloss: 0.200215\n",
      "[90]\ttraining's binary_logloss: 0.202006\tvalid_1's binary_logloss: 0.207536\n",
      "[349]\ttraining's binary_logloss: 0.179916\tvalid_1's binary_logloss: 0.200208\n",
      "[91]\ttraining's binary_logloss: 0.201903\tvalid_1's binary_logloss: 0.207483\n",
      "[350]\ttraining's binary_logloss: 0.179876\tvalid_1's binary_logloss: 0.200205\n",
      "[92]\ttraining's binary_logloss: 0.201803\tvalid_1's binary_logloss: 0.207432\n",
      "[351]\ttraining's binary_logloss: 0.179834\tvalid_1's binary_logloss: 0.200196\n",
      "[93]\ttraining's binary_logloss: 0.201701\tvalid_1's binary_logloss: 0.207378\n",
      "[352]\ttraining's binary_logloss: 0.179795\tvalid_1's binary_logloss: 0.200187\n",
      "[94]\ttraining's binary_logloss: 0.2016\tvalid_1's binary_logloss: 0.207329\n",
      "[353]\ttraining's binary_logloss: 0.179755\tvalid_1's binary_logloss: 0.200181\n",
      "[95]\ttraining's binary_logloss: 0.2015\tvalid_1's binary_logloss: 0.207276\n",
      "[354]\ttraining's binary_logloss: 0.179715\tvalid_1's binary_logloss: 0.200176\n",
      "[96]\ttraining's binary_logloss: 0.20141\tvalid_1's binary_logloss: 0.207236\n",
      "[355]\ttraining's binary_logloss: 0.179676\tvalid_1's binary_logloss: 0.200169\n",
      "[97]\ttraining's binary_logloss: 0.201311\tvalid_1's binary_logloss: 0.207186\n",
      "[356]\ttraining's binary_logloss: 0.179636\tvalid_1's binary_logloss: 0.200164\n",
      "[98]\ttraining's binary_logloss: 0.201211\tvalid_1's binary_logloss: 0.207139\n",
      "[357]\ttraining's binary_logloss: 0.179596\tvalid_1's binary_logloss: 0.200161\n",
      "[99]\ttraining's binary_logloss: 0.201121\tvalid_1's binary_logloss: 0.207101\n",
      "[358]\ttraining's binary_logloss: 0.179557\tvalid_1's binary_logloss: 0.200158\n",
      "[100]\ttraining's binary_logloss: 0.201026\tvalid_1's binary_logloss: 0.207055\n",
      "[359]\ttraining's binary_logloss: 0.179518\tvalid_1's binary_logloss: 0.200152\n",
      "[101]\ttraining's binary_logloss: 0.200929\tvalid_1's binary_logloss: 0.207005\n",
      "[360]\ttraining's binary_logloss: 0.179479\tvalid_1's binary_logloss: 0.200146\n",
      "[102]\ttraining's binary_logloss: 0.200829\tvalid_1's binary_logloss: 0.20696\n",
      "[103]\ttraining's binary_logloss: 0.200733\tvalid_1's binary_logloss: 0.206913\n",
      "[104]\ttraining's binary_logloss: 0.200637\tvalid_1's binary_logloss: 0.206872\n",
      "[105]\ttraining's binary_logloss: 0.20054\tvalid_1's binary_logloss: 0.206827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 16:42:12,220]\u001b[0m Trial 13 finished with value: 0.7067501323033507 and parameters: {'n_estimators': 360, 'num_leaves': 183, 'max_depth': 92, 'learning_rate': 0.004784825503565179, 'min_split_gain': 0.018240148242843462, 'feature_fraction': 0.9948916043934378, 'bagging_freq': 1}. Best is trial 1 with value: 0.7079213160266236.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106]\ttraining's binary_logloss: 0.200445\tvalid_1's binary_logloss: 0.206781\n",
      "[107]\ttraining's binary_logloss: 0.200352\tvalid_1's binary_logloss: 0.206738\n",
      "[108]\ttraining's binary_logloss: 0.200257\tvalid_1's binary_logloss: 0.206691\n",
      "[109]\ttraining's binary_logloss: 0.200162\tvalid_1's binary_logloss: 0.206645\n",
      "[110]\ttraining's binary_logloss: 0.200069\tvalid_1's binary_logloss: 0.206598\n",
      "[111]\ttraining's binary_logloss: 0.199978\tvalid_1's binary_logloss: 0.206556\n",
      "[112]\ttraining's binary_logloss: 0.199885\tvalid_1's binary_logloss: 0.206512\n",
      "[113]\ttraining's binary_logloss: 0.199794\tvalid_1's binary_logloss: 0.206464\n",
      "[114]\ttraining's binary_logloss: 0.199704\tvalid_1's binary_logloss: 0.206422\n",
      "[115]\ttraining's binary_logloss: 0.199614\tvalid_1's binary_logloss: 0.206381\n",
      "[116]\ttraining's binary_logloss: 0.199523\tvalid_1's binary_logloss: 0.206342\n",
      "[117]\ttraining's binary_logloss: 0.19943\tvalid_1's binary_logloss: 0.206295\n",
      "[118]\ttraining's binary_logloss: 0.199339\tvalid_1's binary_logloss: 0.20625\n",
      "[119]\ttraining's binary_logloss: 0.199248\tvalid_1's binary_logloss: 0.206206\n",
      "[120]\ttraining's binary_logloss: 0.199157\tvalid_1's binary_logloss: 0.206162\n",
      "[121]\ttraining's binary_logloss: 0.199068\tvalid_1's binary_logloss: 0.206115\n",
      "[122]\ttraining's binary_logloss: 0.198981\tvalid_1's binary_logloss: 0.206074\n",
      "[123]\ttraining's binary_logloss: 0.198895\tvalid_1's binary_logloss: 0.206032\n",
      "[124]\ttraining's binary_logloss: 0.19881\tvalid_1's binary_logloss: 0.205993\n",
      "[125]\ttraining's binary_logloss: 0.198726\tvalid_1's binary_logloss: 0.205953\n",
      "[126]\ttraining's binary_logloss: 0.198643\tvalid_1's binary_logloss: 0.205914\n",
      "[127]\ttraining's binary_logloss: 0.19856\tvalid_1's binary_logloss: 0.205874\n",
      "[128]\ttraining's binary_logloss: 0.198478\tvalid_1's binary_logloss: 0.205835\n",
      "[129]\ttraining's binary_logloss: 0.198395\tvalid_1's binary_logloss: 0.205796\n",
      "[130]\ttraining's binary_logloss: 0.198315\tvalid_1's binary_logloss: 0.205757\n",
      "[131]\ttraining's binary_logloss: 0.198233\tvalid_1's binary_logloss: 0.205719\n",
      "[132]\ttraining's binary_logloss: 0.198152\tvalid_1's binary_logloss: 0.205678\n",
      "[133]\ttraining's binary_logloss: 0.198072\tvalid_1's binary_logloss: 0.205639\n",
      "[134]\ttraining's binary_logloss: 0.197993\tvalid_1's binary_logloss: 0.205601\n",
      "[135]\ttraining's binary_logloss: 0.197914\tvalid_1's binary_logloss: 0.205563\n",
      "[136]\ttraining's binary_logloss: 0.19783\tvalid_1's binary_logloss: 0.205522\n",
      "[137]\ttraining's binary_logloss: 0.197748\tvalid_1's binary_logloss: 0.205483\n",
      "[138]\ttraining's binary_logloss: 0.197665\tvalid_1's binary_logloss: 0.205443\n",
      "[139]\ttraining's binary_logloss: 0.197584\tvalid_1's binary_logloss: 0.205406\n",
      "[140]\ttraining's binary_logloss: 0.197503\tvalid_1's binary_logloss: 0.205368\n",
      "[141]\ttraining's binary_logloss: 0.197424\tvalid_1's binary_logloss: 0.205332\n",
      "[142]\ttraining's binary_logloss: 0.197343\tvalid_1's binary_logloss: 0.20529\n",
      "[143]\ttraining's binary_logloss: 0.197262\tvalid_1's binary_logloss: 0.205249\n",
      "[144]\ttraining's binary_logloss: 0.197182\tvalid_1's binary_logloss: 0.205206\n",
      "[145]\ttraining's binary_logloss: 0.197101\tvalid_1's binary_logloss: 0.205165\n",
      "[146]\ttraining's binary_logloss: 0.197029\tvalid_1's binary_logloss: 0.205138\n",
      "[147]\ttraining's binary_logloss: 0.19695\tvalid_1's binary_logloss: 0.205098\n",
      "[148]\ttraining's binary_logloss: 0.196871\tvalid_1's binary_logloss: 0.205056\n",
      "[149]\ttraining's binary_logloss: 0.196794\tvalid_1's binary_logloss: 0.205015\n",
      "[150]\ttraining's binary_logloss: 0.196716\tvalid_1's binary_logloss: 0.204974\n",
      "[151]\ttraining's binary_logloss: 0.19664\tvalid_1's binary_logloss: 0.204937\n",
      "[152]\ttraining's binary_logloss: 0.196564\tvalid_1's binary_logloss: 0.204899\n",
      "[153]\ttraining's binary_logloss: 0.196488\tvalid_1's binary_logloss: 0.204861\n",
      "[154]\ttraining's binary_logloss: 0.196414\tvalid_1's binary_logloss: 0.204821\n",
      "[155]\ttraining's binary_logloss: 0.19634\tvalid_1's binary_logloss: 0.204783\n",
      "[156]\ttraining's binary_logloss: 0.196266\tvalid_1's binary_logloss: 0.204742\n",
      "[157]\ttraining's binary_logloss: 0.196193\tvalid_1's binary_logloss: 0.204704\n",
      "[158]\ttraining's binary_logloss: 0.19612\tvalid_1's binary_logloss: 0.204667\n",
      "[159]\ttraining's binary_logloss: 0.196048\tvalid_1's binary_logloss: 0.204627\n",
      "[160]\ttraining's binary_logloss: 0.195977\tvalid_1's binary_logloss: 0.204589\n",
      "[161]\ttraining's binary_logloss: 0.195905\tvalid_1's binary_logloss: 0.204549\n",
      "[162]\ttraining's binary_logloss: 0.195833\tvalid_1's binary_logloss: 0.204512\n",
      "[163]\ttraining's binary_logloss: 0.195761\tvalid_1's binary_logloss: 0.204472\n",
      "[164]\ttraining's binary_logloss: 0.195691\tvalid_1's binary_logloss: 0.204437\n",
      "[165]\ttraining's binary_logloss: 0.195621\tvalid_1's binary_logloss: 0.204402\n",
      "[166]\ttraining's binary_logloss: 0.195551\tvalid_1's binary_logloss: 0.204369\n",
      "[167]\ttraining's binary_logloss: 0.195481\tvalid_1's binary_logloss: 0.204331\n",
      "[168]\ttraining's binary_logloss: 0.195412\tvalid_1's binary_logloss: 0.204298\n",
      "[169]\ttraining's binary_logloss: 0.195343\tvalid_1's binary_logloss: 0.204264\n",
      "[170]\ttraining's binary_logloss: 0.195275\tvalid_1's binary_logloss: 0.204233\n",
      "[171]\ttraining's binary_logloss: 0.195206\tvalid_1's binary_logloss: 0.204197\n",
      "[172]\ttraining's binary_logloss: 0.195138\tvalid_1's binary_logloss: 0.204169\n",
      "[173]\ttraining's binary_logloss: 0.19507\tvalid_1's binary_logloss: 0.204132\n",
      "[174]\ttraining's binary_logloss: 0.195001\tvalid_1's binary_logloss: 0.204098\n",
      "[175]\ttraining's binary_logloss: 0.194933\tvalid_1's binary_logloss: 0.204063\n",
      "[176]\ttraining's binary_logloss: 0.194866\tvalid_1's binary_logloss: 0.204029\n",
      "[177]\ttraining's binary_logloss: 0.194798\tvalid_1's binary_logloss: 0.203994\n",
      "[178]\ttraining's binary_logloss: 0.194731\tvalid_1's binary_logloss: 0.203954\n",
      "[179]\ttraining's binary_logloss: 0.194665\tvalid_1's binary_logloss: 0.203917\n",
      "[180]\ttraining's binary_logloss: 0.194599\tvalid_1's binary_logloss: 0.203884\n",
      "[181]\ttraining's binary_logloss: 0.194531\tvalid_1's binary_logloss: 0.203855\n",
      "[182]\ttraining's binary_logloss: 0.194465\tvalid_1's binary_logloss: 0.203821\n",
      "[183]\ttraining's binary_logloss: 0.1944\tvalid_1's binary_logloss: 0.20379\n",
      "[184]\ttraining's binary_logloss: 0.194335\tvalid_1's binary_logloss: 0.203756\n",
      "[185]\ttraining's binary_logloss: 0.194269\tvalid_1's binary_logloss: 0.203726\n",
      "[186]\ttraining's binary_logloss: 0.194201\tvalid_1's binary_logloss: 0.203691\n",
      "[187]\ttraining's binary_logloss: 0.194136\tvalid_1's binary_logloss: 0.203658\n",
      "[188]\ttraining's binary_logloss: 0.194072\tvalid_1's binary_logloss: 0.203627\n",
      "[189]\ttraining's binary_logloss: 0.194012\tvalid_1's binary_logloss: 0.203606\n",
      "[190]\ttraining's binary_logloss: 0.193948\tvalid_1's binary_logloss: 0.203572\n",
      "[191]\ttraining's binary_logloss: 0.193886\tvalid_1's binary_logloss: 0.203544\n",
      "[192]\ttraining's binary_logloss: 0.193823\tvalid_1's binary_logloss: 0.203511\n",
      "[193]\ttraining's binary_logloss: 0.193761\tvalid_1's binary_logloss: 0.203483\n",
      "[194]\ttraining's binary_logloss: 0.193696\tvalid_1's binary_logloss: 0.203452\n",
      "[195]\ttraining's binary_logloss: 0.193631\tvalid_1's binary_logloss: 0.203422\n",
      "[196]\ttraining's binary_logloss: 0.193566\tvalid_1's binary_logloss: 0.203394\n",
      "[197]\ttraining's binary_logloss: 0.193502\tvalid_1's binary_logloss: 0.203365\n",
      "[198]\ttraining's binary_logloss: 0.193439\tvalid_1's binary_logloss: 0.203337\n",
      "[199]\ttraining's binary_logloss: 0.193375\tvalid_1's binary_logloss: 0.203311\n",
      "[200]\ttraining's binary_logloss: 0.193315\tvalid_1's binary_logloss: 0.203281\n",
      "[201]\ttraining's binary_logloss: 0.193252\tvalid_1's binary_logloss: 0.203253\n",
      "[202]\ttraining's binary_logloss: 0.19319\tvalid_1's binary_logloss: 0.203226\n",
      "[203]\ttraining's binary_logloss: 0.193128\tvalid_1's binary_logloss: 0.2032\n",
      "[204]\ttraining's binary_logloss: 0.193068\tvalid_1's binary_logloss: 0.203172\n",
      "[205]\ttraining's binary_logloss: 0.193006\tvalid_1's binary_logloss: 0.203144\n",
      "[206]\ttraining's binary_logloss: 0.192944\tvalid_1's binary_logloss: 0.20312\n",
      "[207]\ttraining's binary_logloss: 0.192883\tvalid_1's binary_logloss: 0.203094\n",
      "[208]\ttraining's binary_logloss: 0.192824\tvalid_1's binary_logloss: 0.203067\n",
      "[209]\ttraining's binary_logloss: 0.192763\tvalid_1's binary_logloss: 0.20304\n",
      "[210]\ttraining's binary_logloss: 0.192704\tvalid_1's binary_logloss: 0.203016\n",
      "[211]\ttraining's binary_logloss: 0.192644\tvalid_1's binary_logloss: 0.202991\n",
      "[212]\ttraining's binary_logloss: 0.192585\tvalid_1's binary_logloss: 0.20297\n",
      "[213]\ttraining's binary_logloss: 0.192528\tvalid_1's binary_logloss: 0.202943\n",
      "[214]\ttraining's binary_logloss: 0.192469\tvalid_1's binary_logloss: 0.202915\n",
      "[215]\ttraining's binary_logloss: 0.19241\tvalid_1's binary_logloss: 0.202892\n",
      "[216]\ttraining's binary_logloss: 0.19235\tvalid_1's binary_logloss: 0.20287\n",
      "[217]\ttraining's binary_logloss: 0.192295\tvalid_1's binary_logloss: 0.202842\n",
      "[218]\ttraining's binary_logloss: 0.192235\tvalid_1's binary_logloss: 0.202818\n",
      "[219]\ttraining's binary_logloss: 0.192178\tvalid_1's binary_logloss: 0.202794\n",
      "[220]\ttraining's binary_logloss: 0.19212\tvalid_1's binary_logloss: 0.202768\n",
      "[221]\ttraining's binary_logloss: 0.192063\tvalid_1's binary_logloss: 0.202742\n",
      "[222]\ttraining's binary_logloss: 0.192003\tvalid_1's binary_logloss: 0.202718\n",
      "[223]\ttraining's binary_logloss: 0.191945\tvalid_1's binary_logloss: 0.202695\n",
      "[224]\ttraining's binary_logloss: 0.191886\tvalid_1's binary_logloss: 0.20267\n",
      "[225]\ttraining's binary_logloss: 0.19183\tvalid_1's binary_logloss: 0.202645\n",
      "[226]\ttraining's binary_logloss: 0.191774\tvalid_1's binary_logloss: 0.202622\n",
      "[227]\ttraining's binary_logloss: 0.191715\tvalid_1's binary_logloss: 0.202596\n",
      "[228]\ttraining's binary_logloss: 0.191659\tvalid_1's binary_logloss: 0.202571\n",
      "[229]\ttraining's binary_logloss: 0.191603\tvalid_1's binary_logloss: 0.202545\n",
      "[230]\ttraining's binary_logloss: 0.191548\tvalid_1's binary_logloss: 0.202524\n",
      "[231]\ttraining's binary_logloss: 0.191489\tvalid_1's binary_logloss: 0.2025\n",
      "[232]\ttraining's binary_logloss: 0.191434\tvalid_1's binary_logloss: 0.202479\n",
      "[233]\ttraining's binary_logloss: 0.19138\tvalid_1's binary_logloss: 0.20246\n",
      "[234]\ttraining's binary_logloss: 0.191325\tvalid_1's binary_logloss: 0.202437\n",
      "[235]\ttraining's binary_logloss: 0.191272\tvalid_1's binary_logloss: 0.202418\n",
      "[236]\ttraining's binary_logloss: 0.191218\tvalid_1's binary_logloss: 0.202401\n",
      "[237]\ttraining's binary_logloss: 0.191162\tvalid_1's binary_logloss: 0.202378\n",
      "[238]\ttraining's binary_logloss: 0.191109\tvalid_1's binary_logloss: 0.20236\n",
      "[239]\ttraining's binary_logloss: 0.191056\tvalid_1's binary_logloss: 0.202342\n",
      "[240]\ttraining's binary_logloss: 0.191005\tvalid_1's binary_logloss: 0.202327\n",
      "[241]\ttraining's binary_logloss: 0.190952\tvalid_1's binary_logloss: 0.202306\n",
      "[242]\ttraining's binary_logloss: 0.190898\tvalid_1's binary_logloss: 0.202284\n",
      "[243]\ttraining's binary_logloss: 0.190846\tvalid_1's binary_logloss: 0.202262\n",
      "[244]\ttraining's binary_logloss: 0.190794\tvalid_1's binary_logloss: 0.202242\n",
      "[245]\ttraining's binary_logloss: 0.190741\tvalid_1's binary_logloss: 0.202219\n",
      "[246]\ttraining's binary_logloss: 0.190689\tvalid_1's binary_logloss: 0.202199\n",
      "[247]\ttraining's binary_logloss: 0.190638\tvalid_1's binary_logloss: 0.20218\n",
      "[248]\ttraining's binary_logloss: 0.190586\tvalid_1's binary_logloss: 0.202164\n",
      "[249]\ttraining's binary_logloss: 0.190532\tvalid_1's binary_logloss: 0.202145\n",
      "[250]\ttraining's binary_logloss: 0.190481\tvalid_1's binary_logloss: 0.202129\n",
      "[251]\ttraining's binary_logloss: 0.19043\tvalid_1's binary_logloss: 0.202108\n",
      "[252]\ttraining's binary_logloss: 0.190378\tvalid_1's binary_logloss: 0.20209\n",
      "[253]\ttraining's binary_logloss: 0.190327\tvalid_1's binary_logloss: 0.202074\n",
      "[254]\ttraining's binary_logloss: 0.190276\tvalid_1's binary_logloss: 0.202059\n",
      "[255]\ttraining's binary_logloss: 0.190227\tvalid_1's binary_logloss: 0.202042\n",
      "[256]\ttraining's binary_logloss: 0.190174\tvalid_1's binary_logloss: 0.202023\n",
      "[257]\ttraining's binary_logloss: 0.190124\tvalid_1's binary_logloss: 0.202007\n",
      "[258]\ttraining's binary_logloss: 0.190075\tvalid_1's binary_logloss: 0.20199\n",
      "[259]\ttraining's binary_logloss: 0.190025\tvalid_1's binary_logloss: 0.201973\n",
      "[260]\ttraining's binary_logloss: 0.189976\tvalid_1's binary_logloss: 0.201957\n",
      "[261]\ttraining's binary_logloss: 0.189926\tvalid_1's binary_logloss: 0.201937\n",
      "[262]\ttraining's binary_logloss: 0.189876\tvalid_1's binary_logloss: 0.201916\n",
      "[263]\ttraining's binary_logloss: 0.189826\tvalid_1's binary_logloss: 0.201896\n",
      "[264]\ttraining's binary_logloss: 0.189774\tvalid_1's binary_logloss: 0.201874\n",
      "[265]\ttraining's binary_logloss: 0.189723\tvalid_1's binary_logloss: 0.201853\n",
      "[266]\ttraining's binary_logloss: 0.189672\tvalid_1's binary_logloss: 0.201832\n",
      "[267]\ttraining's binary_logloss: 0.189622\tvalid_1's binary_logloss: 0.201812\n",
      "[268]\ttraining's binary_logloss: 0.189573\tvalid_1's binary_logloss: 0.201791\n",
      "[269]\ttraining's binary_logloss: 0.189523\tvalid_1's binary_logloss: 0.201772\n",
      "[270]\ttraining's binary_logloss: 0.189475\tvalid_1's binary_logloss: 0.201754\n",
      "[271]\ttraining's binary_logloss: 0.189426\tvalid_1's binary_logloss: 0.201736\n",
      "[272]\ttraining's binary_logloss: 0.189377\tvalid_1's binary_logloss: 0.20172\n",
      "[273]\ttraining's binary_logloss: 0.18933\tvalid_1's binary_logloss: 0.201702\n",
      "[274]\ttraining's binary_logloss: 0.189282\tvalid_1's binary_logloss: 0.20168\n",
      "[275]\ttraining's binary_logloss: 0.189233\tvalid_1's binary_logloss: 0.201662\n",
      "[276]\ttraining's binary_logloss: 0.189185\tvalid_1's binary_logloss: 0.201643\n",
      "[277]\ttraining's binary_logloss: 0.189137\tvalid_1's binary_logloss: 0.201622\n",
      "[278]\ttraining's binary_logloss: 0.189089\tvalid_1's binary_logloss: 0.201605\n",
      "[279]\ttraining's binary_logloss: 0.189041\tvalid_1's binary_logloss: 0.201586\n",
      "[280]\ttraining's binary_logloss: 0.188993\tvalid_1's binary_logloss: 0.201567\n",
      "[281]\ttraining's binary_logloss: 0.188946\tvalid_1's binary_logloss: 0.201551\n",
      "[282]\ttraining's binary_logloss: 0.1889\tvalid_1's binary_logloss: 0.201533\n",
      "[283]\ttraining's binary_logloss: 0.188853\tvalid_1's binary_logloss: 0.201512\n",
      "[284]\ttraining's binary_logloss: 0.188807\tvalid_1's binary_logloss: 0.201496\n",
      "[285]\ttraining's binary_logloss: 0.18876\tvalid_1's binary_logloss: 0.201479\n",
      "[286]\ttraining's binary_logloss: 0.188713\tvalid_1's binary_logloss: 0.201459\n",
      "[287]\ttraining's binary_logloss: 0.188667\tvalid_1's binary_logloss: 0.20144\n",
      "[288]\ttraining's binary_logloss: 0.188622\tvalid_1's binary_logloss: 0.201423\n",
      "[289]\ttraining's binary_logloss: 0.188575\tvalid_1's binary_logloss: 0.201404\n",
      "[290]\ttraining's binary_logloss: 0.188529\tvalid_1's binary_logloss: 0.201383\n",
      "[291]\ttraining's binary_logloss: 0.188482\tvalid_1's binary_logloss: 0.201362\n",
      "[292]\ttraining's binary_logloss: 0.188437\tvalid_1's binary_logloss: 0.201343\n",
      "[293]\ttraining's binary_logloss: 0.188392\tvalid_1's binary_logloss: 0.201325\n",
      "[294]\ttraining's binary_logloss: 0.188346\tvalid_1's binary_logloss: 0.201311\n",
      "[295]\ttraining's binary_logloss: 0.188301\tvalid_1's binary_logloss: 0.201293\n",
      "[296]\ttraining's binary_logloss: 0.188255\tvalid_1's binary_logloss: 0.201278\n",
      "[297]\ttraining's binary_logloss: 0.188209\tvalid_1's binary_logloss: 0.20126\n",
      "[298]\ttraining's binary_logloss: 0.188165\tvalid_1's binary_logloss: 0.201245\n",
      "[299]\ttraining's binary_logloss: 0.188119\tvalid_1's binary_logloss: 0.201229\n",
      "[300]\ttraining's binary_logloss: 0.188074\tvalid_1's binary_logloss: 0.201213\n",
      "[301]\ttraining's binary_logloss: 0.18803\tvalid_1's binary_logloss: 0.201199\n",
      "[302]\ttraining's binary_logloss: 0.187985\tvalid_1's binary_logloss: 0.201185\n",
      "[303]\ttraining's binary_logloss: 0.187941\tvalid_1's binary_logloss: 0.201171\n",
      "[304]\ttraining's binary_logloss: 0.187896\tvalid_1's binary_logloss: 0.201156\n",
      "[305]\ttraining's binary_logloss: 0.187851\tvalid_1's binary_logloss: 0.201141\n",
      "[306]\ttraining's binary_logloss: 0.187806\tvalid_1's binary_logloss: 0.201125\n",
      "[307]\ttraining's binary_logloss: 0.187763\tvalid_1's binary_logloss: 0.201107\n",
      "[308]\ttraining's binary_logloss: 0.187718\tvalid_1's binary_logloss: 0.201089\n",
      "[309]\ttraining's binary_logloss: 0.187673\tvalid_1's binary_logloss: 0.201074\n",
      "[310]\ttraining's binary_logloss: 0.18763\tvalid_1's binary_logloss: 0.20106\n",
      "[311]\ttraining's binary_logloss: 0.187587\tvalid_1's binary_logloss: 0.201045\n",
      "[312]\ttraining's binary_logloss: 0.187544\tvalid_1's binary_logloss: 0.201029\n",
      "[313]\ttraining's binary_logloss: 0.187501\tvalid_1's binary_logloss: 0.201017\n",
      "[314]\ttraining's binary_logloss: 0.187458\tvalid_1's binary_logloss: 0.201003\n",
      "[315]\ttraining's binary_logloss: 0.187416\tvalid_1's binary_logloss: 0.20099\n",
      "[316]\ttraining's binary_logloss: 0.187371\tvalid_1's binary_logloss: 0.200976\n",
      "[317]\ttraining's binary_logloss: 0.187329\tvalid_1's binary_logloss: 0.200964\n",
      "[318]\ttraining's binary_logloss: 0.187286\tvalid_1's binary_logloss: 0.200951\n",
      "[319]\ttraining's binary_logloss: 0.187243\tvalid_1's binary_logloss: 0.200938\n",
      "[320]\ttraining's binary_logloss: 0.187201\tvalid_1's binary_logloss: 0.200924\n",
      "[321]\ttraining's binary_logloss: 0.187159\tvalid_1's binary_logloss: 0.200913\n",
      "[322]\ttraining's binary_logloss: 0.187114\tvalid_1's binary_logloss: 0.200898\n",
      "[323]\ttraining's binary_logloss: 0.187073\tvalid_1's binary_logloss: 0.200885\n",
      "[324]\ttraining's binary_logloss: 0.187031\tvalid_1's binary_logloss: 0.200873\n",
      "[325]\ttraining's binary_logloss: 0.18699\tvalid_1's binary_logloss: 0.20086\n",
      "[326]\ttraining's binary_logloss: 0.186949\tvalid_1's binary_logloss: 0.200848\n",
      "[327]\ttraining's binary_logloss: 0.186908\tvalid_1's binary_logloss: 0.200834\n",
      "[328]\ttraining's binary_logloss: 0.186868\tvalid_1's binary_logloss: 0.200826\n",
      "[329]\ttraining's binary_logloss: 0.186828\tvalid_1's binary_logloss: 0.200813\n",
      "[330]\ttraining's binary_logloss: 0.186788\tvalid_1's binary_logloss: 0.200802\n",
      "[331]\ttraining's binary_logloss: 0.186747\tvalid_1's binary_logloss: 0.20079\n",
      "[332]\ttraining's binary_logloss: 0.186707\tvalid_1's binary_logloss: 0.20078\n",
      "[333]\ttraining's binary_logloss: 0.186667\tvalid_1's binary_logloss: 0.200768\n",
      "[334]\ttraining's binary_logloss: 0.186627\tvalid_1's binary_logloss: 0.200756\n",
      "[335]\ttraining's binary_logloss: 0.186585\tvalid_1's binary_logloss: 0.200744\n",
      "[336]\ttraining's binary_logloss: 0.186546\tvalid_1's binary_logloss: 0.200735\n",
      "[337]\ttraining's binary_logloss: 0.186506\tvalid_1's binary_logloss: 0.200722\n",
      "[338]\ttraining's binary_logloss: 0.186465\tvalid_1's binary_logloss: 0.200713\n",
      "[339]\ttraining's binary_logloss: 0.186426\tvalid_1's binary_logloss: 0.200703\n",
      "[340]\ttraining's binary_logloss: 0.186386\tvalid_1's binary_logloss: 0.20069\n",
      "[341]\ttraining's binary_logloss: 0.186346\tvalid_1's binary_logloss: 0.200679\n",
      "[342]\ttraining's binary_logloss: 0.186307\tvalid_1's binary_logloss: 0.20067\n",
      "[343]\ttraining's binary_logloss: 0.186268\tvalid_1's binary_logloss: 0.200657\n",
      "[344]\ttraining's binary_logloss: 0.186229\tvalid_1's binary_logloss: 0.200644\n",
      "[345]\ttraining's binary_logloss: 0.186189\tvalid_1's binary_logloss: 0.200634\n",
      "[346]\ttraining's binary_logloss: 0.186153\tvalid_1's binary_logloss: 0.200627\n",
      "[347]\ttraining's binary_logloss: 0.186114\tvalid_1's binary_logloss: 0.200616\n",
      "[348]\ttraining's binary_logloss: 0.186075\tvalid_1's binary_logloss: 0.200604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.215129\tvalid_1's binary_logloss: 0.215196\n",
      "[2]\ttraining's binary_logloss: 0.214893\tvalid_1's binary_logloss: 0.215043\n",
      "[3]\ttraining's binary_logloss: 0.214661\tvalid_1's binary_logloss: 0.214894\n",
      "[4]\ttraining's binary_logloss: 0.214434\tvalid_1's binary_logloss: 0.214753\n",
      "[5]\ttraining's binary_logloss: 0.214211\tvalid_1's binary_logloss: 0.214614\n",
      "[6]\ttraining's binary_logloss: 0.214002\tvalid_1's binary_logloss: 0.21448\n",
      "[7]\ttraining's binary_logloss: 0.213781\tvalid_1's binary_logloss: 0.214343\n",
      "[8]\ttraining's binary_logloss: 0.213565\tvalid_1's binary_logloss: 0.214205\n",
      "[9]\ttraining's binary_logloss: 0.213359\tvalid_1's binary_logloss: 0.214078\n",
      "[10]\ttraining's binary_logloss: 0.213149\tvalid_1's binary_logloss: 0.213944\n",
      "[11]\ttraining's binary_logloss: 0.212943\tvalid_1's binary_logloss: 0.213811\n",
      "[12]\ttraining's binary_logloss: 0.21274\tvalid_1's binary_logloss: 0.213686\n",
      "[13]\ttraining's binary_logloss: 0.212538\tvalid_1's binary_logloss: 0.213559\n",
      "[14]\ttraining's binary_logloss: 0.212338\tvalid_1's binary_logloss: 0.213439\n",
      "[15]\ttraining's binary_logloss: 0.212142\tvalid_1's binary_logloss: 0.213312\n",
      "[16]\ttraining's binary_logloss: 0.211949\tvalid_1's binary_logloss: 0.213189\n",
      "[17]\ttraining's binary_logloss: 0.211759\tvalid_1's binary_logloss: 0.213071\n",
      "[18]\ttraining's binary_logloss: 0.21157\tvalid_1's binary_logloss: 0.212948\n",
      "[19]\ttraining's binary_logloss: 0.211386\tvalid_1's binary_logloss: 0.212835\n",
      "[20]\ttraining's binary_logloss: 0.211205\tvalid_1's binary_logloss: 0.212727\n",
      "[21]\ttraining's binary_logloss: 0.211026\tvalid_1's binary_logloss: 0.212616\n",
      "[22]\ttraining's binary_logloss: 0.210849\tvalid_1's binary_logloss: 0.212504\n",
      "[23]\ttraining's binary_logloss: 0.210676\tvalid_1's binary_logloss: 0.212399\n",
      "[24]\ttraining's binary_logloss: 0.210507\tvalid_1's binary_logloss: 0.212293\n",
      "[25]\ttraining's binary_logloss: 0.210341\tvalid_1's binary_logloss: 0.212194\n",
      "[26]\ttraining's binary_logloss: 0.210175\tvalid_1's binary_logloss: 0.212094\n",
      "[27]\ttraining's binary_logloss: 0.210008\tvalid_1's binary_logloss: 0.211992\n",
      "[28]\ttraining's binary_logloss: 0.209844\tvalid_1's binary_logloss: 0.211897\n",
      "[29]\ttraining's binary_logloss: 0.209686\tvalid_1's binary_logloss: 0.211801\n",
      "[30]\ttraining's binary_logloss: 0.209526\tvalid_1's binary_logloss: 0.211706\n",
      "[31]\ttraining's binary_logloss: 0.209369\tvalid_1's binary_logloss: 0.211615\n",
      "[32]\ttraining's binary_logloss: 0.209212\tvalid_1's binary_logloss: 0.211524\n",
      "[33]\ttraining's binary_logloss: 0.20906\tvalid_1's binary_logloss: 0.211436\n",
      "[34]\ttraining's binary_logloss: 0.208907\tvalid_1's binary_logloss: 0.211341\n",
      "[35]\ttraining's binary_logloss: 0.208756\tvalid_1's binary_logloss: 0.211253\n",
      "[36]\ttraining's binary_logloss: 0.208607\tvalid_1's binary_logloss: 0.211167\n",
      "[37]\ttraining's binary_logloss: 0.20846\tvalid_1's binary_logloss: 0.211081\n",
      "[38]\ttraining's binary_logloss: 0.208314\tvalid_1's binary_logloss: 0.211\n",
      "[39]\ttraining's binary_logloss: 0.208169\tvalid_1's binary_logloss: 0.210917\n",
      "[40]\ttraining's binary_logloss: 0.208024\tvalid_1's binary_logloss: 0.210832\n",
      "[41]\ttraining's binary_logloss: 0.207877\tvalid_1's binary_logloss: 0.210748\n",
      "[42]\ttraining's binary_logloss: 0.207732\tvalid_1's binary_logloss: 0.210664\n",
      "[43]\ttraining's binary_logloss: 0.207588\tvalid_1's binary_logloss: 0.210575\n",
      "[44]\ttraining's binary_logloss: 0.207446\tvalid_1's binary_logloss: 0.210493\n",
      "[45]\ttraining's binary_logloss: 0.207301\tvalid_1's binary_logloss: 0.210405\n",
      "[46]\ttraining's binary_logloss: 0.207159\tvalid_1's binary_logloss: 0.210321\n",
      "[47]\ttraining's binary_logloss: 0.207018\tvalid_1's binary_logloss: 0.210238\n",
      "[48]\ttraining's binary_logloss: 0.206881\tvalid_1's binary_logloss: 0.210158\n",
      "[49]\ttraining's binary_logloss: 0.206743\tvalid_1's binary_logloss: 0.210076\n",
      "[50]\ttraining's binary_logloss: 0.206607\tvalid_1's binary_logloss: 0.209992\n",
      "[51]\ttraining's binary_logloss: 0.206472\tvalid_1's binary_logloss: 0.209912\n",
      "[52]\ttraining's binary_logloss: 0.206338\tvalid_1's binary_logloss: 0.209838\n",
      "[53]\ttraining's binary_logloss: 0.206206\tvalid_1's binary_logloss: 0.209755\n",
      "[54]\ttraining's binary_logloss: 0.206073\tvalid_1's binary_logloss: 0.209673\n",
      "[55]\ttraining's binary_logloss: 0.205942\tvalid_1's binary_logloss: 0.209595\n",
      "[56]\ttraining's binary_logloss: 0.205814\tvalid_1's binary_logloss: 0.209519\n",
      "[57]\ttraining's binary_logloss: 0.205686\tvalid_1's binary_logloss: 0.209444\n",
      "[58]\ttraining's binary_logloss: 0.205559\tvalid_1's binary_logloss: 0.209367\n",
      "[59]\ttraining's binary_logloss: 0.205436\tvalid_1's binary_logloss: 0.209293\n",
      "[60]\ttraining's binary_logloss: 0.20531\tvalid_1's binary_logloss: 0.209219\n",
      "[61]\ttraining's binary_logloss: 0.205188\tvalid_1's binary_logloss: 0.209154\n",
      "[62]\ttraining's binary_logloss: 0.205066\tvalid_1's binary_logloss: 0.209087\n",
      "[63]\ttraining's binary_logloss: 0.204947\tvalid_1's binary_logloss: 0.209013\n",
      "[64]\ttraining's binary_logloss: 0.204819\tvalid_1's binary_logloss: 0.208935\n",
      "[65]\ttraining's binary_logloss: 0.204694\tvalid_1's binary_logloss: 0.20886\n",
      "[66]\ttraining's binary_logloss: 0.204571\tvalid_1's binary_logloss: 0.208789\n",
      "[67]\ttraining's binary_logloss: 0.204446\tvalid_1's binary_logloss: 0.208711\n",
      "[68]\ttraining's binary_logloss: 0.204323\tvalid_1's binary_logloss: 0.208636\n",
      "[69]\ttraining's binary_logloss: 0.204202\tvalid_1's binary_logloss: 0.208561\n",
      "[70]\ttraining's binary_logloss: 0.204083\tvalid_1's binary_logloss: 0.208485\n",
      "[71]\ttraining's binary_logloss: 0.203967\tvalid_1's binary_logloss: 0.208416\n",
      "[72]\ttraining's binary_logloss: 0.20385\tvalid_1's binary_logloss: 0.208345\n",
      "[73]\ttraining's binary_logloss: 0.203733\tvalid_1's binary_logloss: 0.208277\n",
      "[74]\ttraining's binary_logloss: 0.203618\tvalid_1's binary_logloss: 0.208213\n",
      "[75]\ttraining's binary_logloss: 0.203503\tvalid_1's binary_logloss: 0.208149\n",
      "[76]\ttraining's binary_logloss: 0.203389\tvalid_1's binary_logloss: 0.208079\n",
      "[77]\ttraining's binary_logloss: 0.203278\tvalid_1's binary_logloss: 0.208013\n",
      "[78]\ttraining's binary_logloss: 0.203166\tvalid_1's binary_logloss: 0.207952\n",
      "[79]\ttraining's binary_logloss: 0.203055\tvalid_1's binary_logloss: 0.207886\n",
      "[80]\ttraining's binary_logloss: 0.202945\tvalid_1's binary_logloss: 0.207822\n",
      "[81]\ttraining's binary_logloss: 0.202839\tvalid_1's binary_logloss: 0.207762\n",
      "[82]\ttraining's binary_logloss: 0.202731\tvalid_1's binary_logloss: 0.207703\n",
      "[83]\ttraining's binary_logloss: 0.202623\tvalid_1's binary_logloss: 0.207646\n",
      "[84]\ttraining's binary_logloss: 0.202515\tvalid_1's binary_logloss: 0.207583\n",
      "[85]\ttraining's binary_logloss: 0.202411\tvalid_1's binary_logloss: 0.207523\n",
      "[86]\ttraining's binary_logloss: 0.202305\tvalid_1's binary_logloss: 0.207465\n",
      "[87]\ttraining's binary_logloss: 0.202199\tvalid_1's binary_logloss: 0.207405\n",
      "[88]\ttraining's binary_logloss: 0.202096\tvalid_1's binary_logloss: 0.207348\n",
      "[89]\ttraining's binary_logloss: 0.201994\tvalid_1's binary_logloss: 0.207291\n",
      "[90]\ttraining's binary_logloss: 0.201892\tvalid_1's binary_logloss: 0.207237\n",
      "[91]\ttraining's binary_logloss: 0.201791\tvalid_1's binary_logloss: 0.207184\n",
      "[92]\ttraining's binary_logloss: 0.20169\tvalid_1's binary_logloss: 0.20713\n",
      "[93]\ttraining's binary_logloss: 0.201591\tvalid_1's binary_logloss: 0.207079\n",
      "[94]\ttraining's binary_logloss: 0.201491\tvalid_1's binary_logloss: 0.207025\n",
      "[95]\ttraining's binary_logloss: 0.201392\tvalid_1's binary_logloss: 0.20697\n",
      "[96]\ttraining's binary_logloss: 0.201301\tvalid_1's binary_logloss: 0.206931\n",
      "[97]\ttraining's binary_logloss: 0.201204\tvalid_1's binary_logloss: 0.206878\n",
      "[98]\ttraining's binary_logloss: 0.201106\tvalid_1's binary_logloss: 0.206822\n",
      "[99]\ttraining's binary_logloss: 0.201016\tvalid_1's binary_logloss: 0.206786\n",
      "[100]\ttraining's binary_logloss: 0.200918\tvalid_1's binary_logloss: 0.206732\n",
      "[101]\ttraining's binary_logloss: 0.20082\tvalid_1's binary_logloss: 0.206677\n",
      "[102]\ttraining's binary_logloss: 0.200724\tvalid_1's binary_logloss: 0.206626\n",
      "[103]\ttraining's binary_logloss: 0.20063\tvalid_1's binary_logloss: 0.206574\n",
      "[104]\ttraining's binary_logloss: 0.200534\tvalid_1's binary_logloss: 0.20652\n",
      "[105]\ttraining's binary_logloss: 0.200441\tvalid_1's binary_logloss: 0.20647\n",
      "[106]\ttraining's binary_logloss: 0.200347\tvalid_1's binary_logloss: 0.206421\n",
      "[107]\ttraining's binary_logloss: 0.200255\tvalid_1's binary_logloss: 0.206373\n",
      "[108]\ttraining's binary_logloss: 0.200162\tvalid_1's binary_logloss: 0.20632\n",
      "[109]\ttraining's binary_logloss: 0.200071\tvalid_1's binary_logloss: 0.20627\n",
      "[110]\ttraining's binary_logloss: 0.199978\tvalid_1's binary_logloss: 0.20622\n",
      "[111]\ttraining's binary_logloss: 0.199886\tvalid_1's binary_logloss: 0.206168\n",
      "[112]\ttraining's binary_logloss: 0.199796\tvalid_1's binary_logloss: 0.206115\n",
      "[113]\ttraining's binary_logloss: 0.199705\tvalid_1's binary_logloss: 0.206061\n",
      "[114]\ttraining's binary_logloss: 0.199616\tvalid_1's binary_logloss: 0.206012\n",
      "[115]\ttraining's binary_logloss: 0.199527\tvalid_1's binary_logloss: 0.205962\n",
      "[116]\ttraining's binary_logloss: 0.199438\tvalid_1's binary_logloss: 0.205914\n",
      "[117]\ttraining's binary_logloss: 0.19935\tvalid_1's binary_logloss: 0.205867\n",
      "[118]\ttraining's binary_logloss: 0.199264\tvalid_1's binary_logloss: 0.205824\n",
      "[119]\ttraining's binary_logloss: 0.199177\tvalid_1's binary_logloss: 0.205773\n",
      "[120]\ttraining's binary_logloss: 0.199089\tvalid_1's binary_logloss: 0.205726\n",
      "[121]\ttraining's binary_logloss: 0.199005\tvalid_1's binary_logloss: 0.205678\n",
      "[122]\ttraining's binary_logloss: 0.198915\tvalid_1's binary_logloss: 0.205628\n",
      "[123]\ttraining's binary_logloss: 0.198829\tvalid_1's binary_logloss: 0.205582\n",
      "[124]\ttraining's binary_logloss: 0.198745\tvalid_1's binary_logloss: 0.205538\n",
      "[125]\ttraining's binary_logloss: 0.198655\tvalid_1's binary_logloss: 0.205492\n",
      "[126]\ttraining's binary_logloss: 0.198572\tvalid_1's binary_logloss: 0.20545\n",
      "[127]\ttraining's binary_logloss: 0.19849\tvalid_1's binary_logloss: 0.205406\n",
      "[128]\ttraining's binary_logloss: 0.198402\tvalid_1's binary_logloss: 0.205359\n",
      "[129]\ttraining's binary_logloss: 0.19832\tvalid_1's binary_logloss: 0.205315\n",
      "[130]\ttraining's binary_logloss: 0.198239\tvalid_1's binary_logloss: 0.205268\n",
      "[131]\ttraining's binary_logloss: 0.198152\tvalid_1's binary_logloss: 0.205224\n",
      "[132]\ttraining's binary_logloss: 0.198065\tvalid_1's binary_logloss: 0.205179\n",
      "[133]\ttraining's binary_logloss: 0.197985\tvalid_1's binary_logloss: 0.205139\n",
      "[134]\ttraining's binary_logloss: 0.197905\tvalid_1's binary_logloss: 0.205099\n",
      "[135]\ttraining's binary_logloss: 0.197819\tvalid_1's binary_logloss: 0.205057\n",
      "[136]\ttraining's binary_logloss: 0.197738\tvalid_1's binary_logloss: 0.205018\n",
      "[137]\ttraining's binary_logloss: 0.197654\tvalid_1's binary_logloss: 0.204975\n",
      "[138]\ttraining's binary_logloss: 0.197575\tvalid_1's binary_logloss: 0.204938\n",
      "[139]\ttraining's binary_logloss: 0.197491\tvalid_1's binary_logloss: 0.204896\n",
      "[140]\ttraining's binary_logloss: 0.197407\tvalid_1's binary_logloss: 0.204854\n",
      "[141]\ttraining's binary_logloss: 0.197329\tvalid_1's binary_logloss: 0.204814\n",
      "[142]\ttraining's binary_logloss: 0.197246\tvalid_1's binary_logloss: 0.204775\n",
      "[143]\ttraining's binary_logloss: 0.197163\tvalid_1's binary_logloss: 0.204733\n",
      "[144]\ttraining's binary_logloss: 0.19708\tvalid_1's binary_logloss: 0.204692\n",
      "[145]\ttraining's binary_logloss: 0.196996\tvalid_1's binary_logloss: 0.20465\n",
      "[146]\ttraining's binary_logloss: 0.196924\tvalid_1's binary_logloss: 0.204622\n",
      "[147]\ttraining's binary_logloss: 0.196844\tvalid_1's binary_logloss: 0.204581\n",
      "[148]\ttraining's binary_logloss: 0.196762\tvalid_1's binary_logloss: 0.204538\n",
      "[149]\ttraining's binary_logloss: 0.19668\tvalid_1's binary_logloss: 0.204495\n",
      "[150]\ttraining's binary_logloss: 0.196599\tvalid_1's binary_logloss: 0.204453\n",
      "[151]\ttraining's binary_logloss: 0.19652\tvalid_1's binary_logloss: 0.20441\n",
      "[152]\ttraining's binary_logloss: 0.196442\tvalid_1's binary_logloss: 0.204369\n",
      "[153]\ttraining's binary_logloss: 0.196365\tvalid_1's binary_logloss: 0.204333\n",
      "[154]\ttraining's binary_logloss: 0.196288\tvalid_1's binary_logloss: 0.204292\n",
      "[155]\ttraining's binary_logloss: 0.196212\tvalid_1's binary_logloss: 0.204251\n",
      "[156]\ttraining's binary_logloss: 0.196136\tvalid_1's binary_logloss: 0.204212\n",
      "[157]\ttraining's binary_logloss: 0.19606\tvalid_1's binary_logloss: 0.204172\n",
      "[158]\ttraining's binary_logloss: 0.195983\tvalid_1's binary_logloss: 0.20413\n",
      "[159]\ttraining's binary_logloss: 0.195909\tvalid_1's binary_logloss: 0.204094\n",
      "[160]\ttraining's binary_logloss: 0.195835\tvalid_1's binary_logloss: 0.204056\n",
      "[161]\ttraining's binary_logloss: 0.195761\tvalid_1's binary_logloss: 0.204018\n",
      "[162]\ttraining's binary_logloss: 0.195688\tvalid_1's binary_logloss: 0.203984\n",
      "[163]\ttraining's binary_logloss: 0.195615\tvalid_1's binary_logloss: 0.203945\n",
      "[164]\ttraining's binary_logloss: 0.195543\tvalid_1's binary_logloss: 0.203909\n",
      "[165]\ttraining's binary_logloss: 0.195471\tvalid_1's binary_logloss: 0.203872\n",
      "[166]\ttraining's binary_logloss: 0.195399\tvalid_1's binary_logloss: 0.203839\n",
      "[167]\ttraining's binary_logloss: 0.195326\tvalid_1's binary_logloss: 0.203805\n",
      "[168]\ttraining's binary_logloss: 0.195254\tvalid_1's binary_logloss: 0.203772\n",
      "[169]\ttraining's binary_logloss: 0.195182\tvalid_1's binary_logloss: 0.203736\n",
      "[170]\ttraining's binary_logloss: 0.195111\tvalid_1's binary_logloss: 0.2037\n",
      "[171]\ttraining's binary_logloss: 0.19504\tvalid_1's binary_logloss: 0.203667\n",
      "[172]\ttraining's binary_logloss: 0.194968\tvalid_1's binary_logloss: 0.203631\n",
      "[173]\ttraining's binary_logloss: 0.194896\tvalid_1's binary_logloss: 0.203593\n",
      "[174]\ttraining's binary_logloss: 0.194827\tvalid_1's binary_logloss: 0.203557\n",
      "[175]\ttraining's binary_logloss: 0.194757\tvalid_1's binary_logloss: 0.20352\n",
      "[176]\ttraining's binary_logloss: 0.194687\tvalid_1's binary_logloss: 0.203482\n",
      "[177]\ttraining's binary_logloss: 0.194619\tvalid_1's binary_logloss: 0.203447\n",
      "[178]\ttraining's binary_logloss: 0.19455\tvalid_1's binary_logloss: 0.203411\n",
      "[179]\ttraining's binary_logloss: 0.194481\tvalid_1's binary_logloss: 0.203377\n",
      "[180]\ttraining's binary_logloss: 0.194412\tvalid_1's binary_logloss: 0.203346\n",
      "[181]\ttraining's binary_logloss: 0.194344\tvalid_1's binary_logloss: 0.203313\n",
      "[182]\ttraining's binary_logloss: 0.194275\tvalid_1's binary_logloss: 0.203283\n",
      "[183]\ttraining's binary_logloss: 0.194208\tvalid_1's binary_logloss: 0.203253\n",
      "[184]\ttraining's binary_logloss: 0.19414\tvalid_1's binary_logloss: 0.203225\n",
      "[185]\ttraining's binary_logloss: 0.194074\tvalid_1's binary_logloss: 0.203197\n",
      "[186]\ttraining's binary_logloss: 0.194007\tvalid_1's binary_logloss: 0.203168\n",
      "[187]\ttraining's binary_logloss: 0.19394\tvalid_1's binary_logloss: 0.203139\n",
      "[188]\ttraining's binary_logloss: 0.193874\tvalid_1's binary_logloss: 0.203111\n",
      "[189]\ttraining's binary_logloss: 0.193813\tvalid_1's binary_logloss: 0.203089\n",
      "[190]\ttraining's binary_logloss: 0.193747\tvalid_1's binary_logloss: 0.203061\n",
      "[191]\ttraining's binary_logloss: 0.193682\tvalid_1's binary_logloss: 0.203034\n",
      "[192]\ttraining's binary_logloss: 0.193617\tvalid_1's binary_logloss: 0.203007\n",
      "[193]\ttraining's binary_logloss: 0.193553\tvalid_1's binary_logloss: 0.202981\n",
      "[194]\ttraining's binary_logloss: 0.193491\tvalid_1's binary_logloss: 0.202954\n",
      "[195]\ttraining's binary_logloss: 0.193428\tvalid_1's binary_logloss: 0.202928\n",
      "[196]\ttraining's binary_logloss: 0.193363\tvalid_1's binary_logloss: 0.202902\n",
      "[197]\ttraining's binary_logloss: 0.193302\tvalid_1's binary_logloss: 0.202876\n",
      "[198]\ttraining's binary_logloss: 0.19324\tvalid_1's binary_logloss: 0.202852\n",
      "[199]\ttraining's binary_logloss: 0.193176\tvalid_1's binary_logloss: 0.202826\n",
      "[200]\ttraining's binary_logloss: 0.193116\tvalid_1's binary_logloss: 0.202801\n",
      "[201]\ttraining's binary_logloss: 0.193054\tvalid_1's binary_logloss: 0.202775\n",
      "[202]\ttraining's binary_logloss: 0.192993\tvalid_1's binary_logloss: 0.202751\n",
      "[203]\ttraining's binary_logloss: 0.192931\tvalid_1's binary_logloss: 0.202726\n",
      "[204]\ttraining's binary_logloss: 0.19287\tvalid_1's binary_logloss: 0.202701\n",
      "[205]\ttraining's binary_logloss: 0.19281\tvalid_1's binary_logloss: 0.202677\n",
      "[206]\ttraining's binary_logloss: 0.192747\tvalid_1's binary_logloss: 0.202649\n",
      "[207]\ttraining's binary_logloss: 0.192685\tvalid_1's binary_logloss: 0.202622\n",
      "[208]\ttraining's binary_logloss: 0.192622\tvalid_1's binary_logloss: 0.202594\n",
      "[209]\ttraining's binary_logloss: 0.192561\tvalid_1's binary_logloss: 0.20257\n",
      "[210]\ttraining's binary_logloss: 0.192499\tvalid_1's binary_logloss: 0.202543\n",
      "[211]\ttraining's binary_logloss: 0.192439\tvalid_1's binary_logloss: 0.202518\n",
      "[212]\ttraining's binary_logloss: 0.192378\tvalid_1's binary_logloss: 0.202492\n",
      "[213]\ttraining's binary_logloss: 0.192319\tvalid_1's binary_logloss: 0.202467\n",
      "[214]\ttraining's binary_logloss: 0.192259\tvalid_1's binary_logloss: 0.202442\n",
      "[215]\ttraining's binary_logloss: 0.192199\tvalid_1's binary_logloss: 0.202415\n",
      "[216]\ttraining's binary_logloss: 0.192141\tvalid_1's binary_logloss: 0.202391\n",
      "[217]\ttraining's binary_logloss: 0.19208\tvalid_1's binary_logloss: 0.202368\n",
      "[218]\ttraining's binary_logloss: 0.192019\tvalid_1's binary_logloss: 0.202343\n",
      "[219]\ttraining's binary_logloss: 0.191959\tvalid_1's binary_logloss: 0.202318\n",
      "[220]\ttraining's binary_logloss: 0.191901\tvalid_1's binary_logloss: 0.202297\n",
      "[221]\ttraining's binary_logloss: 0.191841\tvalid_1's binary_logloss: 0.202273\n",
      "[222]\ttraining's binary_logloss: 0.191783\tvalid_1's binary_logloss: 0.202249\n",
      "[223]\ttraining's binary_logloss: 0.191723\tvalid_1's binary_logloss: 0.202224\n",
      "[224]\ttraining's binary_logloss: 0.191666\tvalid_1's binary_logloss: 0.202203\n",
      "[225]\ttraining's binary_logloss: 0.191609\tvalid_1's binary_logloss: 0.202179\n",
      "[226]\ttraining's binary_logloss: 0.19155\tvalid_1's binary_logloss: 0.202154\n",
      "[227]\ttraining's binary_logloss: 0.191492\tvalid_1's binary_logloss: 0.202127\n",
      "[228]\ttraining's binary_logloss: 0.191436\tvalid_1's binary_logloss: 0.202105\n",
      "[229]\ttraining's binary_logloss: 0.191378\tvalid_1's binary_logloss: 0.202082\n",
      "[230]\ttraining's binary_logloss: 0.191321\tvalid_1's binary_logloss: 0.202058\n",
      "[231]\ttraining's binary_logloss: 0.191263\tvalid_1's binary_logloss: 0.202036\n",
      "[232]\ttraining's binary_logloss: 0.191206\tvalid_1's binary_logloss: 0.202012\n",
      "[233]\ttraining's binary_logloss: 0.19115\tvalid_1's binary_logloss: 0.20199\n",
      "[234]\ttraining's binary_logloss: 0.191093\tvalid_1's binary_logloss: 0.201968\n",
      "[235]\ttraining's binary_logloss: 0.191037\tvalid_1's binary_logloss: 0.201945\n",
      "[236]\ttraining's binary_logloss: 0.190982\tvalid_1's binary_logloss: 0.201924\n",
      "[237]\ttraining's binary_logloss: 0.190926\tvalid_1's binary_logloss: 0.201901\n",
      "[238]\ttraining's binary_logloss: 0.190871\tvalid_1's binary_logloss: 0.201878\n",
      "[239]\ttraining's binary_logloss: 0.190817\tvalid_1's binary_logloss: 0.201858\n",
      "[240]\ttraining's binary_logloss: 0.190766\tvalid_1's binary_logloss: 0.201844\n",
      "[241]\ttraining's binary_logloss: 0.190712\tvalid_1's binary_logloss: 0.20182\n",
      "[242]\ttraining's binary_logloss: 0.190657\tvalid_1's binary_logloss: 0.201797\n",
      "[243]\ttraining's binary_logloss: 0.190605\tvalid_1's binary_logloss: 0.201778\n",
      "[244]\ttraining's binary_logloss: 0.190552\tvalid_1's binary_logloss: 0.201757\n",
      "[245]\ttraining's binary_logloss: 0.190502\tvalid_1's binary_logloss: 0.201737\n",
      "[246]\ttraining's binary_logloss: 0.190447\tvalid_1's binary_logloss: 0.201714\n",
      "[247]\ttraining's binary_logloss: 0.190394\tvalid_1's binary_logloss: 0.201689\n",
      "[248]\ttraining's binary_logloss: 0.190342\tvalid_1's binary_logloss: 0.20167\n",
      "[249]\ttraining's binary_logloss: 0.190291\tvalid_1's binary_logloss: 0.20165\n",
      "[250]\ttraining's binary_logloss: 0.190238\tvalid_1's binary_logloss: 0.20163\n",
      "[251]\ttraining's binary_logloss: 0.190185\tvalid_1's binary_logloss: 0.201607\n",
      "[252]\ttraining's binary_logloss: 0.190133\tvalid_1's binary_logloss: 0.201584\n",
      "[253]\ttraining's binary_logloss: 0.190082\tvalid_1's binary_logloss: 0.201565\n",
      "[254]\ttraining's binary_logloss: 0.19003\tvalid_1's binary_logloss: 0.201546\n",
      "[255]\ttraining's binary_logloss: 0.189977\tvalid_1's binary_logloss: 0.201526\n",
      "[256]\ttraining's binary_logloss: 0.189925\tvalid_1's binary_logloss: 0.201506\n",
      "[257]\ttraining's binary_logloss: 0.189875\tvalid_1's binary_logloss: 0.201485\n",
      "[258]\ttraining's binary_logloss: 0.189823\tvalid_1's binary_logloss: 0.201467\n",
      "[259]\ttraining's binary_logloss: 0.189772\tvalid_1's binary_logloss: 0.20145\n",
      "[260]\ttraining's binary_logloss: 0.189721\tvalid_1's binary_logloss: 0.20143\n",
      "[261]\ttraining's binary_logloss: 0.189669\tvalid_1's binary_logloss: 0.20141\n",
      "[262]\ttraining's binary_logloss: 0.189617\tvalid_1's binary_logloss: 0.201389\n",
      "[263]\ttraining's binary_logloss: 0.189567\tvalid_1's binary_logloss: 0.201373\n",
      "[264]\ttraining's binary_logloss: 0.189516\tvalid_1's binary_logloss: 0.201353\n",
      "[265]\ttraining's binary_logloss: 0.189465\tvalid_1's binary_logloss: 0.201335\n",
      "[266]\ttraining's binary_logloss: 0.189415\tvalid_1's binary_logloss: 0.201318\n",
      "[267]\ttraining's binary_logloss: 0.189365\tvalid_1's binary_logloss: 0.201299\n",
      "[268]\ttraining's binary_logloss: 0.189315\tvalid_1's binary_logloss: 0.20128\n",
      "[269]\ttraining's binary_logloss: 0.189264\tvalid_1's binary_logloss: 0.201263\n",
      "[270]\ttraining's binary_logloss: 0.189215\tvalid_1's binary_logloss: 0.201246\n",
      "[271]\ttraining's binary_logloss: 0.189165\tvalid_1's binary_logloss: 0.201232\n",
      "[272]\ttraining's binary_logloss: 0.189116\tvalid_1's binary_logloss: 0.201212\n",
      "[273]\ttraining's binary_logloss: 0.189067\tvalid_1's binary_logloss: 0.201196\n",
      "[274]\ttraining's binary_logloss: 0.189019\tvalid_1's binary_logloss: 0.201179\n",
      "[275]\ttraining's binary_logloss: 0.18897\tvalid_1's binary_logloss: 0.201163\n",
      "[276]\ttraining's binary_logloss: 0.188923\tvalid_1's binary_logloss: 0.201148\n",
      "[277]\ttraining's binary_logloss: 0.188872\tvalid_1's binary_logloss: 0.201128\n",
      "[278]\ttraining's binary_logloss: 0.188823\tvalid_1's binary_logloss: 0.201113\n",
      "[279]\ttraining's binary_logloss: 0.188774\tvalid_1's binary_logloss: 0.201099\n",
      "[280]\ttraining's binary_logloss: 0.188725\tvalid_1's binary_logloss: 0.201078\n",
      "[281]\ttraining's binary_logloss: 0.188675\tvalid_1's binary_logloss: 0.201065\n",
      "[282]\ttraining's binary_logloss: 0.188627\tvalid_1's binary_logloss: 0.201049\n",
      "[283]\ttraining's binary_logloss: 0.188579\tvalid_1's binary_logloss: 0.201028\n",
      "[284]\ttraining's binary_logloss: 0.188531\tvalid_1's binary_logloss: 0.201012\n",
      "[285]\ttraining's binary_logloss: 0.188484\tvalid_1's binary_logloss: 0.200998\n",
      "[286]\ttraining's binary_logloss: 0.188436\tvalid_1's binary_logloss: 0.200979\n",
      "[287]\ttraining's binary_logloss: 0.188389\tvalid_1's binary_logloss: 0.200965\n",
      "[288]\ttraining's binary_logloss: 0.188343\tvalid_1's binary_logloss: 0.200948\n",
      "[289]\ttraining's binary_logloss: 0.188295\tvalid_1's binary_logloss: 0.200928\n",
      "[290]\ttraining's binary_logloss: 0.18825\tvalid_1's binary_logloss: 0.200915\n",
      "[291]\ttraining's binary_logloss: 0.188203\tvalid_1's binary_logloss: 0.2009\n",
      "[292]\ttraining's binary_logloss: 0.188156\tvalid_1's binary_logloss: 0.200881\n",
      "[293]\ttraining's binary_logloss: 0.18811\tvalid_1's binary_logloss: 0.200868\n",
      "[294]\ttraining's binary_logloss: 0.188062\tvalid_1's binary_logloss: 0.200852\n",
      "[295]\ttraining's binary_logloss: 0.188017\tvalid_1's binary_logloss: 0.20084\n",
      "[296]\ttraining's binary_logloss: 0.187971\tvalid_1's binary_logloss: 0.200822\n",
      "[297]\ttraining's binary_logloss: 0.187925\tvalid_1's binary_logloss: 0.200807\n",
      "[298]\ttraining's binary_logloss: 0.18788\tvalid_1's binary_logloss: 0.200793\n",
      "[299]\ttraining's binary_logloss: 0.187835\tvalid_1's binary_logloss: 0.200777\n",
      "[300]\ttraining's binary_logloss: 0.18779\tvalid_1's binary_logloss: 0.200763\n",
      "[301]\ttraining's binary_logloss: 0.187746\tvalid_1's binary_logloss: 0.200751\n",
      "[302]\ttraining's binary_logloss: 0.187701\tvalid_1's binary_logloss: 0.200733\n",
      "[303]\ttraining's binary_logloss: 0.187655\tvalid_1's binary_logloss: 0.20072\n",
      "[304]\ttraining's binary_logloss: 0.18761\tvalid_1's binary_logloss: 0.200702\n",
      "[305]\ttraining's binary_logloss: 0.187566\tvalid_1's binary_logloss: 0.200688\n",
      "[306]\ttraining's binary_logloss: 0.187522\tvalid_1's binary_logloss: 0.200671\n",
      "[307]\ttraining's binary_logloss: 0.187478\tvalid_1's binary_logloss: 0.200654\n",
      "[308]\ttraining's binary_logloss: 0.187435\tvalid_1's binary_logloss: 0.200639\n",
      "[309]\ttraining's binary_logloss: 0.187391\tvalid_1's binary_logloss: 0.200625\n",
      "[310]\ttraining's binary_logloss: 0.187348\tvalid_1's binary_logloss: 0.200611\n",
      "[311]\ttraining's binary_logloss: 0.187304\tvalid_1's binary_logloss: 0.200598\n",
      "[312]\ttraining's binary_logloss: 0.187262\tvalid_1's binary_logloss: 0.200583\n",
      "[313]\ttraining's binary_logloss: 0.18722\tvalid_1's binary_logloss: 0.200567\n",
      "[314]\ttraining's binary_logloss: 0.187176\tvalid_1's binary_logloss: 0.200551\n",
      "[315]\ttraining's binary_logloss: 0.187133\tvalid_1's binary_logloss: 0.200538\n",
      "[316]\ttraining's binary_logloss: 0.187091\tvalid_1's binary_logloss: 0.200525\n",
      "[317]\ttraining's binary_logloss: 0.187049\tvalid_1's binary_logloss: 0.200512\n",
      "[318]\ttraining's binary_logloss: 0.187007\tvalid_1's binary_logloss: 0.200499\n",
      "[319]\ttraining's binary_logloss: 0.186964\tvalid_1's binary_logloss: 0.200481\n",
      "[320]\ttraining's binary_logloss: 0.186923\tvalid_1's binary_logloss: 0.200465\n",
      "[321]\ttraining's binary_logloss: 0.186881\tvalid_1's binary_logloss: 0.200447\n",
      "[322]\ttraining's binary_logloss: 0.186839\tvalid_1's binary_logloss: 0.200431\n",
      "[323]\ttraining's binary_logloss: 0.186797\tvalid_1's binary_logloss: 0.20042\n",
      "[324]\ttraining's binary_logloss: 0.186755\tvalid_1's binary_logloss: 0.200404\n",
      "[325]\ttraining's binary_logloss: 0.186714\tvalid_1's binary_logloss: 0.200386\n",
      "[326]\ttraining's binary_logloss: 0.186674\tvalid_1's binary_logloss: 0.200368\n",
      "[327]\ttraining's binary_logloss: 0.186632\tvalid_1's binary_logloss: 0.200358\n",
      "[328]\ttraining's binary_logloss: 0.18659\tvalid_1's binary_logloss: 0.200345\n",
      "[329]\ttraining's binary_logloss: 0.18655\tvalid_1's binary_logloss: 0.20033\n",
      "[330]\ttraining's binary_logloss: 0.186509\tvalid_1's binary_logloss: 0.200316\n",
      "[331]\ttraining's binary_logloss: 0.186469\tvalid_1's binary_logloss: 0.200301\n",
      "[332]\ttraining's binary_logloss: 0.186428\tvalid_1's binary_logloss: 0.200292\n",
      "[333]\ttraining's binary_logloss: 0.186387\tvalid_1's binary_logloss: 0.20028\n",
      "[334]\ttraining's binary_logloss: 0.186347\tvalid_1's binary_logloss: 0.200263\n",
      "[335]\ttraining's binary_logloss: 0.186306\tvalid_1's binary_logloss: 0.200253\n",
      "[336]\ttraining's binary_logloss: 0.186266\tvalid_1's binary_logloss: 0.200243\n",
      "[337]\ttraining's binary_logloss: 0.186226\tvalid_1's binary_logloss: 0.200234\n",
      "[338]\ttraining's binary_logloss: 0.186186\tvalid_1's binary_logloss: 0.200226\n",
      "[339]\ttraining's binary_logloss: 0.186146\tvalid_1's binary_logloss: 0.200215\n",
      "[340]\ttraining's binary_logloss: 0.186106\tvalid_1's binary_logloss: 0.200202\n",
      "[341]\ttraining's binary_logloss: 0.186065\tvalid_1's binary_logloss: 0.200192\n",
      "[342]\ttraining's binary_logloss: 0.186025\tvalid_1's binary_logloss: 0.20018\n",
      "[343]\ttraining's binary_logloss: 0.185986\tvalid_1's binary_logloss: 0.200169\n",
      "[344]\ttraining's binary_logloss: 0.185946\tvalid_1's binary_logloss: 0.200158\n",
      "[345]\ttraining's binary_logloss: 0.185907\tvalid_1's binary_logloss: 0.200147\n",
      "[346]\ttraining's binary_logloss: 0.185869\tvalid_1's binary_logloss: 0.200137\n",
      "[347]\ttraining's binary_logloss: 0.18583\tvalid_1's binary_logloss: 0.200124\n",
      "[348]\ttraining's binary_logloss: 0.18579\tvalid_1's binary_logloss: 0.200114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-25 16:42:29,825]\u001b[0m Trial 14 finished with value: 0.7054562595282902 and parameters: {'n_estimators': 348, 'num_leaves': 180, 'max_depth': 89, 'learning_rate': 0.0032375959903458004, 'min_split_gain': 0.01604239048031275, 'feature_fraction': 0.9854252900019601, 'bagging_freq': 0}. Best is trial 1 with value: 0.7079213160266236.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:103\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(futures) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_jobs:\n\u001b[1;32m--> 103\u001b[0m     completed, futures \u001b[39m=\u001b[39m wait(futures, return_when\u001b[39m=\u001b[39;49mFIRST_COMPLETED)\n\u001b[0;32m    104\u001b[0m     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\concurrent\\futures\\_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(fs, timeout, return_when)\u001b[0m\n\u001b[0;32m    305\u001b[0m     waiter \u001b[39m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[1;32m--> 307\u001b[0m waiter\u001b[39m.\u001b[39;49mevent\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    308\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fs:\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 574\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m     gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick_\\Desktop\\MMAProject\\Fraud Detection - Zindi.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick_/Desktop/MMAProject/Fraud%20Detection%20-%20Zindi.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, sampler \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, pruner \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick_/Desktop/MMAProject/Fraud%20Detection%20-%20Zindi.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, show_progress_bar \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick_/Desktop/MMAProject/Fraud%20Detection%20-%20Zindi.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick_/Desktop/MMAProject/Fraud%20Detection%20-%20Zindi.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest params:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m _optimize(\n\u001b[0;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    410\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:108\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n\u001b[0;32m    106\u001b[0m                         f\u001b[39m.\u001b[39mresult()\n\u001b[1;32m--> 108\u001b[0m                 futures\u001b[39m.\u001b[39madd(\n\u001b[0;32m    109\u001b[0m                     executor\u001b[39m.\u001b[39msubmit(\n\u001b[0;32m    110\u001b[0m                         _optimize_sequential,\n\u001b[0;32m    111\u001b[0m                         study,\n\u001b[0;32m    112\u001b[0m                         func,\n\u001b[0;32m    113\u001b[0m                         \u001b[39m1\u001b[39m,\n\u001b[0;32m    114\u001b[0m                         timeout,\n\u001b[0;32m    115\u001b[0m                         catch,\n\u001b[0;32m    116\u001b[0m                         callbacks,\n\u001b[0;32m    117\u001b[0m                         gc_after_trial,\n\u001b[0;32m    118\u001b[0m                         \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    119\u001b[0m                         time_start,\n\u001b[0;32m    120\u001b[0m                         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    121\u001b[0m                     )\n\u001b[0;32m    122\u001b[0m                 )\n\u001b[0;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     study\u001b[39m.\u001b[39m_optimize_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\concurrent\\futures\\_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m--> 637\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    638\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\concurrent\\futures\\thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[1;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1053\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1073\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1074\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1075\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler = None, pruner = None)\n",
    "study.optimize(objective, n_jobs=2, show_progress_bar = True)\n",
    "\n",
    "print()\n",
    "print(\"Best params:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba1bfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(n_estimators=672, num_leaves=46, max_depth=125, \n",
    "                       learning_rate=0.018141379194639352, min_split_gain=0.05197891962284165, \n",
    "                       feature_fraction=0.545050546948007, bagging_freq=2)\n",
    "\n",
    "stkfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "def calc(X, y, model, cv):\n",
    "    res=[]\n",
    "    local_probs=pd.DataFrame()\n",
    "    probs = pd.DataFrame()\n",
    "\n",
    "    for i, (tdx, vdx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                 early_stopping_rounds=30, verbose=False)\n",
    "        \n",
    "        preds = model.predict_proba(X_valid)\n",
    "        oof_predict = model.predict_proba(test_df)\n",
    "        local_probs['fold_%i'%i] = oof_predict[:,1]\n",
    "        res.append(roc_auc_score(y_valid, preds[:,1]))\n",
    "\n",
    "    print('ROC AUC:', round(np.mean(res), 6))    \n",
    "    local_probs['res'] = local_probs.mean(axis=1)\n",
    "    probs['target'] = local_probs['res']\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b90441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.545050546948007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.545050546948007\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_freq=2, feature_fraction=0.545050546948007,\n",
       "               learning_rate=0.018141379194639352, max_depth=125,\n",
       "               min_split_gain=0.05197891962284165, n_estimators=672,\n",
       "               num_leaves=46)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_all = LGBMClassifier(n_estimators=672, num_leaves=46, max_depth=125, \n",
    "                       learning_rate=0.018141379194639352, min_split_gain=0.05197891962284165, \n",
    "                       feature_fraction=0.545050546948007, bagging_freq=2)\n",
    "clf_all.fit(X, y)\n",
    "\n",
    "y_pred_dt = clf_all.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08736dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127925      2]\n",
      " [  6544   1022]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y, y_pred_dt, target_names=class_names))\n",
    "print(confusion_matrix(y, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "583eff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98    127927\n",
      "         1.0       1.00      0.14      0.24      7566\n",
      "\n",
      "    accuracy                           0.95    135493\n",
      "   macro avg       0.97      0.57      0.61    135493\n",
      "weighted avg       0.95      0.95      0.93    135493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_names = [str(x) for x in clf_all.classes_]\n",
    "print(classification_report(y, y_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e041daaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.545050546948007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.545050546948007\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.545050546948007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.545050546948007\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.545050546948007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.545050546948007\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.545050546948007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.545050546948007\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.545050546948007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.545050546948007\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "d:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.71144\n",
      "CPU times: total: 9min 27s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "probs = calc(X, y, model, stkfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef3ee6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"client_id\": sample_submission[\"client_id\"],\n",
    "        \"target\": probs['target']\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3e06d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.036125\n",
      "1        0.217057\n",
      "2        0.030098\n",
      "3        0.007280\n",
      "4        0.051619\n",
      "           ...   \n",
      "58064    0.034047\n",
      "58065    0.064392\n",
      "58066    0.042540\n",
      "58067    0.016612\n",
      "58068    0.075902\n",
      "Name: target, Length: 58069, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(probs['target'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
