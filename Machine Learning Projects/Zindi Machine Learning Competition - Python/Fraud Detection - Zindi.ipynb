{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb198a7",
   "metadata": {},
   "source": [
    "Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9530f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import itertools\n",
    "\n",
    "import scipy\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd4344f3",
   "metadata": {},
   "source": [
    "# Data ingestion\n",
    "\n",
    "Convert csvs to Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b908663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887059, 16) (864499, 16) (58069, 5) (135493, 6)\n"
     ]
    }
   ],
   "source": [
    "invoice_test = pd.read_csv('invoice_test.csv', low_memory=False)\n",
    "invoice_train = pd.read_csv('invoice_train.csv', low_memory=False)\n",
    "client_test = pd.read_csv('client_test.csv', low_memory=False)\n",
    "client_train = pd.read_csv('client_train.csv', low_memory=False)\n",
    "sample_submission = pd.read_csv('SampleSubmission.csv', low_memory=False)\n",
    "\n",
    "print(invoice_test.shape, invoice_train.shape, client_test.shape, client_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd256e",
   "metadata": {},
   "source": [
    "Data Exploration: This page: https://zindi.africa/competitions/ai-hack-tunisia-4-predictive-analytics-challenge-1/data has the data dictionary. I'm using \"target\" as my label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d56d0769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   disrict        135493 non-null  int64  \n",
      " 1   client_id      135493 non-null  object \n",
      " 2   client_catg    135493 non-null  int64  \n",
      " 3   region         135493 non-null  int64  \n",
      " 4   creation_date  135493 non-null  object \n",
      " 5   target         135493 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "client_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f85dc67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 864499 entries, 0 to 864498\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   client_id             864499 non-null  object\n",
      " 1   invoice_date          864499 non-null  object\n",
      " 2   tarif_type            864499 non-null  int64 \n",
      " 3   counter_number        864499 non-null  int64 \n",
      " 4   counter_statue        864499 non-null  int64 \n",
      " 5   counter_code          864499 non-null  int64 \n",
      " 6   reading_remarque      864499 non-null  int64 \n",
      " 7   counter_coefficient   864499 non-null  int64 \n",
      " 8   consommation_level_1  864499 non-null  int64 \n",
      " 9   consommation_level_2  864499 non-null  int64 \n",
      " 10  consommation_level_3  864499 non-null  int64 \n",
      " 11  consommation_level_4  864499 non-null  int64 \n",
      " 12  old_index             864499 non-null  int64 \n",
      " 13  new_index             864499 non-null  int64 \n",
      " 14  months_number         864499 non-null  int64 \n",
      " 15  counter_type          864498 non-null  object\n",
      "dtypes: int64(13), object(3)\n",
      "memory usage: 105.5+ MB\n"
     ]
    }
   ],
   "source": [
    "invoice_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da21a8ef",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Recoding certain columns, formats, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4eee4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_change(cl, inv):\n",
    "\n",
    "    cl['client_catg'] = cl['client_catg'].astype('category')\n",
    "    cl['disrict'] = cl['disrict'].astype('category')\n",
    "    cl['region'] = cl['region'].astype('category')\n",
    "    cl['region_group'] = cl['region'].apply(lambda x: 100 if x<100 else 300 if x>300 else 200)\n",
    "    cl['creation_date'] = pd.to_datetime(cl['creation_date'])\n",
    "    \n",
    "    cl['coop_time'] = (2019 - cl['creation_date'].dt.year)*12 - cl['creation_date'].dt.month\n",
    "\n",
    "    inv['counter_type'] = inv['counter_type'].map({\"ELEC\":1,\"GAZ\":0})\n",
    "    inv['counter_statue'] = inv['counter_statue'].map({0:0,1:1,2:2,3:3,4:4,5:5,769:5,'0':0,'5':5,'1':1,'4':4,'A':0,618:5,269375:5,46:5,420:5})\n",
    "    \n",
    "    inv['invoice_date'] = pd.to_datetime(inv['invoice_date'], dayfirst=True)\n",
    "    inv['invoice_month'] = inv['invoice_date'].dt.month\n",
    "    inv['invoice_year'] = inv['invoice_date'].dt.year\n",
    "    inv['is_weekday'] = ((pd.DatetimeIndex(inv.invoice_date).dayofweek) // 5 == 1).astype(float)\n",
    "    inv['delta_index'] = inv['new_index'] - inv['old_index']\n",
    "    \n",
    "    return cl, inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8789c3a4",
   "metadata": {},
   "source": [
    "I apply my feature changes to the training and test data. After this point, I don't touch my testing data to prevent leakeage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85071729",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train1, invoice_train1 = feature_change(client_train, invoice_train)\n",
    "client_test1, invoice_test1 = feature_change(client_test, invoice_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ca430",
   "metadata": {},
   "source": [
    "I write a function to create aggregate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1e13d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_feature(invoice, client_df, agg_stat):\n",
    "    \n",
    "    invoice['delta_time'] = invoice.sort_values(['client_id','invoice_date']).groupby('client_id')['invoice_date'].diff().dt.days.reset_index(drop=True)\n",
    "    agg_trans = invoice.groupby('client_id')[agg_stat+['delta_time']].agg(['mean','std','min','max'])\n",
    "    \n",
    "    agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "\n",
    "    df = invoice.groupby('client_id').size().reset_index(name='transactions_count')\n",
    "    agg_trans = pd.merge(df, agg_trans, on='client_id', how='left')\n",
    "    \n",
    "    weekday_avg = invoice.groupby('client_id')[['is_weekday']].agg(['mean'])\n",
    "    weekday_avg.columns = ['_'.join(col).strip() for col in weekday_avg.columns.values]\n",
    "    weekday_avg.reset_index(inplace=True)\n",
    "    client_df = pd.merge(client_df, weekday_avg, on='client_id', how='left')\n",
    "    \n",
    "    full_df = pd.merge(client_df, agg_trans, on='client_id', how='left')\n",
    "    \n",
    "    full_df['invoice_per_cooperation'] = full_df['transactions_count'] / full_df['coop_time']\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ef64e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {}\n",
    "aggs['consommation_level_1'] = ['mean']\n",
    "aggs['consommation_level_2'] = ['mean']\n",
    "aggs['consommation_level_3'] = ['mean']\n",
    "aggs['consommation_level_4'] = ['mean']\n",
    "agg_trans = invoice_train.groupby(['client_id', 'counter_type']).agg(aggs)\n",
    "agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "agg_trans.reset_index(inplace=True)\n",
    "\n",
    "agg_trans1 = agg_trans\n",
    "\n",
    "aggs = {}\n",
    "aggs['consommation_level_1_mean'] = ['mean']\n",
    "aggs['consommation_level_2_mean'] = ['mean']\n",
    "aggs['consommation_level_3_mean'] = ['mean']\n",
    "aggs['consommation_level_4_mean'] = ['mean']\n",
    "agg_trans = agg_trans1.groupby(['client_id']).agg(aggs)\n",
    "agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "agg_trans.reset_index(inplace=True)\n",
    "\n",
    "df = (invoice_train.groupby('client_id')\n",
    "          .size()\n",
    "          .reset_index(name='{}transactions_count'.format('1')))\n",
    "agg_trans = pd.merge(df, agg_trans, on='client_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed92769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stat_columns = [\n",
    " 'tarif_type',\n",
    " 'counter_number',\n",
    " 'counter_statue',\n",
    " 'counter_code',\n",
    " 'reading_remarque',\n",
    " 'consommation_level_1',\n",
    " 'consommation_level_2',\n",
    " 'consommation_level_3',\n",
    " 'consommation_level_4',\n",
    " 'old_index',\n",
    " 'new_index',\n",
    " 'months_number',\n",
    " 'counter_type',\n",
    " 'invoice_month',\n",
    " 'invoice_year',\n",
    " 'delta_index'\n",
    "]\n",
    "\n",
    "train_df1 = agg_feature(invoice_train1, client_train1, agg_stat_columns)\n",
    "test_df1 = agg_feature(invoice_test1, client_test1, agg_stat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b6219",
   "metadata": {},
   "source": [
    "I merge my dataframe with my new aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c35f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['disrict', 'client_id', 'client_catg', 'region', 'creation_date',\n",
      "       'target', 'region_group', 'coop_time', 'is_weekday_mean',\n",
      "       'transactions_count', 'tarif_type_mean', 'tarif_type_std',\n",
      "       'tarif_type_min', 'tarif_type_max', 'counter_number_mean',\n",
      "       'counter_number_std', 'counter_number_min', 'counter_number_max',\n",
      "       'counter_statue_mean', 'counter_statue_std', 'counter_statue_min',\n",
      "       'counter_statue_max', 'counter_code_mean', 'counter_code_std',\n",
      "       'counter_code_min', 'counter_code_max', 'reading_remarque_mean',\n",
      "       'reading_remarque_std', 'reading_remarque_min', 'reading_remarque_max',\n",
      "       'consommation_level_1_mean', 'consommation_level_1_std',\n",
      "       'consommation_level_1_min', 'consommation_level_1_max',\n",
      "       'consommation_level_2_mean', 'consommation_level_2_std',\n",
      "       'consommation_level_2_min', 'consommation_level_2_max',\n",
      "       'consommation_level_3_mean', 'consommation_level_3_std',\n",
      "       'consommation_level_3_min', 'consommation_level_3_max',\n",
      "       'consommation_level_4_mean', 'consommation_level_4_std',\n",
      "       'consommation_level_4_min', 'consommation_level_4_max',\n",
      "       'old_index_mean', 'old_index_std', 'old_index_min', 'old_index_max',\n",
      "       'new_index_mean', 'new_index_std', 'new_index_min', 'new_index_max',\n",
      "       'months_number_mean', 'months_number_std', 'months_number_min',\n",
      "       'months_number_max', 'counter_type_mean', 'counter_type_std',\n",
      "       'counter_type_min', 'counter_type_max', 'invoice_month_mean',\n",
      "       'invoice_month_std', 'invoice_month_min', 'invoice_month_max',\n",
      "       'invoice_year_mean', 'invoice_year_std', 'invoice_year_min',\n",
      "       'invoice_year_max', 'delta_index_mean', 'delta_index_std',\n",
      "       'delta_index_min', 'delta_index_max', 'delta_time_mean',\n",
      "       'delta_time_std', 'delta_time_min', 'delta_time_max',\n",
      "       'invoice_per_cooperation', '1transactions_count',\n",
      "       'consommation_level_1_mean_mean', 'consommation_level_2_mean_mean',\n",
      "       'consommation_level_3_mean_mean', 'consommation_level_4_mean_mean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df1 = pd.merge(train_df1,agg_trans, on='client_id', how='left')\n",
    "\n",
    "test_df1 = pd.merge(test_df1,agg_trans, on='client_id', how='left')\n",
    "\n",
    "print(train_df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310da2e",
   "metadata": {},
   "source": [
    "One more feature engineering step, I create a range and max mean column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a034bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(df):\n",
    "    \n",
    "    for col in agg_stat_columns:\n",
    "        df[col+'_range'] = df[col+'_max'] - df[col+'_min']\n",
    "        df[col+'_max_mean'] = df[col+'_max']/df[col+'_mean']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3b045a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = new_features(train_df1)\n",
    "test_df2 = new_features(test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d973279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of columns:  29\n",
      "Number of columns now:  116\n"
     ]
    }
   ],
   "source": [
    "print('Initial number of columns: ', len(client_train.columns)+len(invoice_train.columns))\n",
    "print('Number of columns now: ', len(train_df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d45401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(df):\n",
    "\n",
    "    col_drop = ['client_id', 'creation_date']\n",
    "    for col in col_drop:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20231590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = drop(train_df2)\n",
    "test_df = drop(test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df6212a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "X = train_df.drop('target',axis=1)\n",
    "\n",
    "feature_name = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a039f17",
   "metadata": {},
   "source": [
    "Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72c9e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=['reading_remarque_max','counter_statue_min','counter_type_min','counter_type_max','counter_type_range',\n",
    "          'tarif_type_max', 'delta_index_min', 'consommation_level_4_mean']\n",
    "\n",
    "X = X.drop(drop_col, axis=1)\n",
    "test_df = test_df.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594293e",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b45a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "import gc\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial:Trial):\n",
    "    \n",
    "    gc.collect()\n",
    "    models=[]\n",
    "    validScore=0\n",
    "   \n",
    "    model,log = fitLGBM(trial,X,y)\n",
    "    \n",
    "    models.append(model)\n",
    "    gc.collect()\n",
    "    validScore+=log\n",
    "    validScore/=len(models)\n",
    "    \n",
    "    return validScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2736aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fitLGBM(trial,X, y):\n",
    "    \n",
    "    params={\n",
    "        'n_estimators':trial.suggest_int('n_estimators', 0, 1000),\n",
    "        'num_leaves':trial.suggest_int('num_leaves', 2, 512),\n",
    "        'max_depth':trial.suggest_int('max_depth', 2, 128),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.5),\n",
    "        'min_split_gain': trial.suggest_loguniform('min_split_gain', 0.001, 0.1),\n",
    "        'feature_fraction':trial.suggest_uniform('feature_fraction',0.1, 1.0),\n",
    "        'bagging_freq':trial.suggest_int('bagging_freq',0.1,10),\n",
    "        'verbosity': -1,\n",
    "            }\n",
    "    stkfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    res=[]\n",
    "    for i, (tdx, vdx) in enumerate(stkfold.split(X, y)):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                 early_stopping_rounds=30)\n",
    "        preds = model.predict_proba(X_valid)\n",
    "        res.append(roc_auc_score(y_valid, preds[:,1]))\n",
    "    \n",
    "    err = np.mean(res)\n",
    "    \n",
    "    return model, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09630c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler = None, pruner = None)\n",
    "study.optimize(objective, n_jobs=2, show_progress_bar = True)\n",
    "\n",
    "print()\n",
    "print(\"Best params:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba1bfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(n_estimators=672, num_leaves=46, max_depth=125, \n",
    "                       learning_rate=0.018141379194639352, min_split_gain=0.05197891962284165, \n",
    "                       feature_fraction=0.545050546948007, bagging_freq=2)\n",
    "\n",
    "stkfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "def calc(X, y, model, cv):\n",
    "    res=[]\n",
    "    local_probs=pd.DataFrame()\n",
    "    probs = pd.DataFrame()\n",
    "\n",
    "    for i, (tdx, vdx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                 early_stopping_rounds=30, verbose=False)\n",
    "        \n",
    "        preds = model.predict_proba(X_valid)\n",
    "        oof_predict = model.predict_proba(test_df)\n",
    "        local_probs['fold_%i'%i] = oof_predict[:,1]\n",
    "        res.append(roc_auc_score(y_valid, preds[:,1]))\n",
    "\n",
    "    print('ROC AUC:', round(np.mean(res), 6))    \n",
    "    local_probs['res'] = local_probs.mean(axis=1)\n",
    "    probs['target'] = local_probs['res']\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b90441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.545050546948007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.545050546948007\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_freq=2, feature_fraction=0.545050546948007,\n",
       "               learning_rate=0.018141379194639352, max_depth=125,\n",
       "               min_split_gain=0.05197891962284165, n_estimators=672,\n",
       "               num_leaves=46)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_all = LGBMClassifier(n_estimators=672, num_leaves=46, max_depth=125, \n",
    "                       learning_rate=0.018141379194639352, min_split_gain=0.05197891962284165, \n",
    "                       feature_fraction=0.545050546948007, bagging_freq=2)\n",
    "clf_all.fit(X, y)\n",
    "\n",
    "y_pred_dt = clf_all.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08736dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127925      2]\n",
      " [  6544   1022]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print(classification_report(y, y_pred_dt, target_names=class_names))\n",
    "print(confusion_matrix(y, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "583eff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98    127927\n",
      "         1.0       1.00      0.14      0.24      7566\n",
      "\n",
      "    accuracy                           0.95    135493\n",
      "   macro avg       0.97      0.57      0.61    135493\n",
      "weighted avg       0.95      0.95      0.93    135493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_names = [str(x) for x in clf_all.classes_]\n",
    "print(classification_report(y, y_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041daaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "probs = calc(X, y, model, stkfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef3ee6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"client_id\": sample_submission[\"client_id\"],\n",
    "        \"target\": probs['target']\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3e06d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.036125\n",
      "1        0.217057\n",
      "2        0.030098\n",
      "3        0.007280\n",
      "4        0.051619\n",
      "           ...   \n",
      "58064    0.034047\n",
      "58065    0.064392\n",
      "58066    0.042540\n",
      "58067    0.016612\n",
      "58068    0.075902\n",
      "Name: target, Length: 58069, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(probs['target'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31660b717a90691fa2150953dc601a0926d4d210e901e02fea65d7e1f048d215"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
